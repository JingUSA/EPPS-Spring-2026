[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "im_sp2026/index.html",
    "href": "im_sp2026/index.html",
    "title": "EPPS 6354 Information Management",
    "section": "",
    "text": "Assignment 1\nAssignment 2"
  },
  {
    "objectID": "im_sp2026/index.html#assignments",
    "href": "im_sp2026/index.html#assignments",
    "title": "EPPS 6354 Information Management",
    "section": "",
    "text": "Assignment 1\nAssignment 2"
  },
  {
    "objectID": "im_sp2026/assignment1.html#q1-3-applications-using-database-systems-for-persistent-data",
    "href": "im_sp2026/assignment1.html#q1-3-applications-using-database-systems-for-persistent-data",
    "title": "EPPS 6354 Assignment 1",
    "section": "Q1: 3 applications using database systems for persistent data",
    "text": "Q1: 3 applications using database systems for persistent data"
  },
  {
    "objectID": "im_sp2026/assignment1.html#application-1-online-banking",
    "href": "im_sp2026/assignment1.html#application-1-online-banking",
    "title": "EPPS 6354 Assignment 1",
    "section": "Application 1: Online Banking",
    "text": "Application 1: Online Banking\nWhat persistent data is stored - Accounts, balances, transaction records, payees, transfers, statements\nHow the database is used - Transactions (ACID) keep transfers consistent (no double charge / missing debit) - Indexing supports fast search by date, amount, merchant - Audit logs support compliance and dispute resolution"
  },
  {
    "objectID": "im_sp2026/assignment1.html#application-2-university-systems-registration-elearning",
    "href": "im_sp2026/assignment1.html#application-2-university-systems-registration-elearning",
    "title": "EPPS 6354 Assignment 1",
    "section": "Application 2: University Systems (Registration / eLearning)",
    "text": "Application 2: University Systems (Registration / eLearning)\nWhat persistent data is stored - Students, courses, enrollments, grades, attendance, submissions\nHow the database is used - Many-to-many relationship: students ↔︎ courses (enrollments table) - Constraints enforce rules (prerequisites, capacity, deadlines) - Queries generate gradebooks, transcripts, and reports"
  },
  {
    "objectID": "im_sp2026/assignment1.html#application-3-e-commerce-amazon-taobao",
    "href": "im_sp2026/assignment1.html#application-3-e-commerce-amazon-taobao",
    "title": "EPPS 6354 Assignment 1",
    "section": "Application 3: E-commerce (Amazon / Taobao)",
    "text": "Application 3: E-commerce (Amazon / Taobao)\nWhat persistent data is stored - Products, inventory, carts, orders, payments, shipping, reviews\nHow the database is used - Tracks order lifecycle + payment/shipping status - Updates inventory and fulfillment information - Supports search/filtering and user history"
  },
  {
    "objectID": "im_sp2026/assignment1.html#q2-3-domain-project-applications-purpose-functions-interface",
    "href": "im_sp2026/assignment1.html#q2-3-domain-project-applications-purpose-functions-interface",
    "title": "EPPS 6354 Assignment 1",
    "section": "Q2: 3 domain project applications (purpose, functions, interface)",
    "text": "Q2: 3 domain project applications (purpose, functions, interface)"
  },
  {
    "objectID": "im_sp2026/assignment1.html#project-1-criminology-case-linkage-system",
    "href": "im_sp2026/assignment1.html#project-1-criminology-case-linkage-system",
    "title": "EPPS 6354 Assignment 1",
    "section": "Project 1: Criminology Case Linkage System",
    "text": "Project 1: Criminology Case Linkage System\nPurpose - Help analysts connect related incidents using patterns (modus operandi, location/time)\nFunctions - Incident intake form (suspect/vehicle/weapon/location/time) - Similarity search + filters (time range, area, category) - Export case packet for investigators\nSimple interface - Left: filters\n- Center: map + timeline\n- Right: ranked “Similar Cases” list + confidence score"
  },
  {
    "objectID": "im_sp2026/assignment1.html#project-2-economics-inflation-household-stress-dashboard",
    "href": "im_sp2026/assignment1.html#project-2-economics-inflation-household-stress-dashboard",
    "title": "EPPS 6354 Assignment 1",
    "section": "Project 2: Economics Inflation & Household Stress Dashboard",
    "text": "Project 2: Economics Inflation & Household Stress Dashboard\nPurpose - Track CPI/wages/unemployment and relate them to household hardship indicators\nFunctions - Import macro indicators + survey hardship measures - Trend charts, regional comparison, automatic short report export\nSimple interface - Top: region + time window - Middle: trend charts + heatmap - Bottom: “Key takeaways” summary box"
  },
  {
    "objectID": "im_sp2026/assignment1.html#project-3-brain-science-health-cohort-tracker",
    "href": "im_sp2026/assignment1.html#project-3-brain-science-health-cohort-tracker",
    "title": "EPPS 6354 Assignment 1",
    "section": "Project 3: Brain Science / Health Cohort Tracker",
    "text": "Project 3: Brain Science / Health Cohort Tracker\nPurpose - Manage longitudinal participant data, visits, and outcomes for a research cohort\nFunctions - Enrollment + visit scheduling - Survey/lab result uploads + validation checks - De-identified export for analysis\nSimple interface - Tabs: Participants | Visits | Measures | Export - Profile page: visit timeline + latest metrics"
  },
  {
    "objectID": "im_sp2026/assignment1.html#q6-at-least-3-tables-for-a-social-networksocial-media-system",
    "href": "im_sp2026/assignment1.html#q6-at-least-3-tables-for-a-social-networksocial-media-system",
    "title": "EPPS 6354 Assignment 1",
    "section": "Q6: At least 3 tables for a social network/social media system",
    "text": "Q6: At least 3 tables for a social network/social media system"
  },
  {
    "objectID": "im_sp2026/assignment1.html#table-1-users",
    "href": "im_sp2026/assignment1.html#table-1-users",
    "title": "EPPS 6354 Assignment 1",
    "section": "Table 1: Users",
    "text": "Table 1: Users\nUsers - user_id (PK) - username (unique), email (unique) - hashed_password - created_at, status (active/banned) - bio, avatar_url"
  },
  {
    "objectID": "im_sp2026/assignment1.html#table-2-posts-and-comments",
    "href": "im_sp2026/assignment1.html#table-2-posts-and-comments",
    "title": "EPPS 6354 Assignment 1",
    "section": "Table 2: Posts and Comments",
    "text": "Table 2: Posts and Comments\nPosts - post_id (PK) - author_id (FK → Users.user_id) - content, created_at - community_id (optional FK)\nComments - comment_id (PK) - post_id (FK → Posts.post_id) - author_id (FK → Users.user_id) - parent_comment_id (nullable) - content, created_at"
  },
  {
    "objectID": "im_sp2026/assignment1.html#table-3-votesreactions-and-optional-follows",
    "href": "im_sp2026/assignment1.html#table-3-votesreactions-and-optional-follows",
    "title": "EPPS 6354 Assignment 1",
    "section": "Table 3: Votes/Reactions (and optional follows)",
    "text": "Table 3: Votes/Reactions (and optional follows)\nVotes - vote_id (PK) - user_id (FK) - target_type (post/comment), target_id - vote_value (+1 / -1) - created_at - Unique: (user_id, target_type, target_id)\nOptional: Follows - follower_id (FK → Users) - followee_id (FK → Users) - created_at"
  },
  {
    "objectID": "im_sp2026/assignment1.html#q4-why-nosql-emerged-in-the-2000s-contrast-with-traditional-databases",
    "href": "im_sp2026/assignment1.html#q4-why-nosql-emerged-in-the-2000s-contrast-with-traditional-databases",
    "title": "EPPS 6354 Assignment 1",
    "section": "Q4: Why NoSQL emerged in the 2000s + contrast with traditional databases",
    "text": "Q4: Why NoSQL emerged in the 2000s + contrast with traditional databases"
  },
  {
    "objectID": "im_sp2026/assignment1.html#why-nosql-emerged-in-the-2000s",
    "href": "im_sp2026/assignment1.html#why-nosql-emerged-in-the-2000s",
    "title": "EPPS 6354 Assignment 1",
    "section": "Why NoSQL emerged in the 2000s",
    "text": "Why NoSQL emerged in the 2000s\nWhy it emerged - Web-scale systems needed massive throughput and horizontal scaling (scale-out) - Data became more flexible / semi-structured (JSON-like), schema changes were frequent - Global users required distributed storage and low-latency access"
  },
  {
    "objectID": "im_sp2026/assignment1.html#nosql-vs-traditional-databases-brief-contrast",
    "href": "im_sp2026/assignment1.html#nosql-vs-traditional-databases-brief-contrast",
    "title": "EPPS 6354 Assignment 1",
    "section": "NoSQL vs Traditional Databases (brief contrast)",
    "text": "NoSQL vs Traditional Databases (brief contrast)\n\nSchema: flexible (NoSQL) vs fixed tables & constraints (RDBMS)\nScaling: easier horizontal scaling vs often scale-up first\nConsistency: often eventual consistency vs strong ACID by default\nQuery model: document/key-value/column/graph vs SQL + joins\nBest for: feeds/logs/content at scale vs strong integrity apps (banking/ERP)"
  },
  {
    "objectID": "km_sp2026/assignment.html",
    "href": "km_sp2026/assignment.html",
    "title": "Assignment 2: Prompt Exercise",
    "section": "",
    "text": "This structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n\n\n\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n\n\n\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability.\n\n\n\n\n\n\nThis systematic literature review examines the application of Data Mining (DM) and Machine Learning (ML) across various real-world domains over the past decade. By synthesizing findings from 45 selected studies, this review identifies key trends in healthcare, finance, and cybersecurity. The analysis reveals a significant shift towards Deep Learning (DL) techniques, although explainability remains a critical gap. A testable hypothesis regarding the trade-off between model complexity and interpretability in high-stakes domains is proposed.\n\n\n\nThe exponential growth of data has catalyzed the adoption of Data Mining (DM) and Machine Learning (ML) technologies across diverse sectors. From predictive analytics in healthcare to fraud detection in finance, these technologies are reshaping decision-making processes. This review aims to systematically analyze the state-of-the-art applications, focusing on methodology, impact, and prevailing challenges.\n\n\n\nThis review follows the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines.\n\n\nA comprehensive search was conducted on IEEE Xplore, ACM Digital Library, and PubMed using the search string: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\") AND (\"Application\" OR \"Real-world\") AND (\"Healthcare\" OR \"Finance\" OR \"Cybersecurity\").\n\n\n\nInclusion Criteria: - Peer-reviewed articles published between 2014 and 2024. - Studies focusing on practical, real-world implementations. - Articles written in English.\nExclusion Criteria: - Purely theoretical papers without empirical validation. - Survey papers (to avoid redundancy). - Non-peer-reviewed white papers.\n\n\n\nData was extracted based on: 1. Domain of Application 2. Algorithms Used 3. Dataset Scale and Type 4. Performance Metrics 5. Reported Challenges\n\n\n\n\n\n\nHealthcare remains the most prolific domain for ML applications. * Diagnostics: Convolutional Neural Networks (CNNs) have achieved parity with human experts in analyzing medical imaging (X-rays, MRIs). * Prognostics: DM techniques are widely used for predicting patient readmission rates and disease progression. * Key Insight: While accuracy is high, clinical adoption is hindered by the “black box” nature of advanced models.\n\n\n\nThe financial sector heavily utilizes DM for risk management and fraud detection. * Fraud Detection: Ensemble methods like Random Forest and Gradient Boosting Machines (GBM) are preferred for their robustness against imbalanced datasets. * Algorithmic Trading: Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are standard for time-series forecasting.\n\n\n\nWith the rise of cyber threats, ML has become integral to intrusion detection systems (IDS). * Anomaly Detection: Unsupervised learning techniques (e.g., K-Means, Autoencoders) are effective in identifying zero-day attacks. * Trend: There is a growing shift towards adversarial machine learning to robustness testing.\n\n\n\n\n\n\n\nShift to Deep Learning: A clear migration from traditional statistical methods (Regression, SVM) to Deep Learning architectures (CNN, Transformer models) across all domains.\nAutoML: Increasing use of Automated Machine Learning tools to democratize AI application for non-experts.\nEdge AI: Deployment of lightweight models on IoT devices, particularly in healthcare monitoring and industrial maintenance.\n\n\n\n\n\nExplainability (XAI): A significant gap exists between model performance and interpretability. In high-stakes domains like law and medicine, this lack of transparency is a barrier to trust and regulatory compliance.\nData Quality and Bias: Many real-world datasets suffer from bias, leading to unfair algorithmic outcomes. Standardization in data preprocessing is lacking.\nScalability: While models perform well in controlled environments, scalability issues often arise during full-scale deployment.\n\n\n\n\n\nBased on the identified gap in Explainable AI (XAI), we propose the following hypothesis:\nHypothesis: In high-stakes decision-making environments (e.g., medical diagnosis, loan approval), the integration of “human-in-the-loop” interactive explainability features will statistically significantly increase user trust and adoption rates compared to black-box models with higher raw accuracy.\nProposed Experiment: * Variables: Independent variable: Type of model interface (Black-box vs. XAI dashboard). Dependent variable: User trust score (Likert scale) and adoption rate. * Method: A/B testing with domain experts using a controlled dataset.\n\n\n\nThis review highlights the transformative power of DM and ML. While technical capabilities have advanced rapidly, the socio-technical challenges of trust, explainability, and bias remain the new frontier for research. Future work must bridge the gap between high-performance algorithms and human-interpretable insights.\n\n\n\n\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.\nEsteva, A., et al. (2017). Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639), 115-118.\nChandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58.\n\n\n\n\n\n\n\nThis systematic literature review examines applications of data mining (DM) and machine learning (ML) across real-world domains from 92 peer-reviewed studies (2019–2024). Following PRISMA guidelines, 1,856 records were screened, yielding high-quality empirical evidence. Key findings reveal deep learning (58%) and ensemble methods (32%) dominating healthcare, finance, transportation, agriculture, manufacturing, and retail, achieving median AUC=0.91 and accuracy=93%. Trends: explainable AI (+42%), federated learning (+380%), edge ML.\nGaps: fairness audits (14%), OOD generalization, model drift.\nHypothesis: Hybrid DM-ML with causal discovery improves OOD F1-scores by ≥18%. (Word count: 112)\n\n\n\nData mining extracts patterns from large datasets using clustering, association rules, and anomaly detection. Machine learning enables predictive modeling via supervised, unsupervised, and reinforcement learning paradigms. Real-world applications span healthcare diagnostics to financial fraud detection, generating economic value exceeding $13 trillion by 2030. Objectives: - Synthesize empirical applications across domains - Identify trends and methodological gaps\n- Propose testable research hypothesis\n\n\n\n\n\nDatabases (April 2024): Scopus, Web of Science, PubMed, IEEE Xplore, ACM DL.\nSearch string: (\"data mining\" OR \"machine learning\") AND (healthcare OR finance OR agriculture) AND (\"real world\" OR \"case study\") AND (2019:2024) Records: 1,856 → screened 1,428 → full-text 312 → included 92 (κ=0.89) ##### 2.2 Inclusion Criteria - Empirical studies with real-world datasets (≥50k instances)\n- Quantitative performance metrics (AUC, F1, accuracy) - Peer-reviewed journals/conferences (2019–2024) ##### 2.3 Quality Assessment Newcastle-Ottawa Scale (modified): High (55%), Moderate (37%), Low (8%)\n\n\n\n\n\n\n\n\n\nDomain\nStudies\nKey Algorithms\nMedian AUC\nExample\n\n\n\n\nHealthcare\n27\nCNN, LSTM\n0.94\nPneumonia detection (94%)\n\n\nFinance\n20\nXGBoost, GNN\n0.93\nFraud detection (99.8%)\n\n\nTransport\n15\nGCN, RL\n0.88\nTraffic forecasting\n\n\nAgriculture\n12\nU-Net, ViT\n0.91\nCrop yield prediction\n\n\nManufacturing\n11\nLSTM\n0.92\nPredictive maintenance\n\n\nRetail\n7\nGraphSAGE\n0.89\nRecommendations\n\n\n\n\n\n\nAggregated metrics (n=92): - Median accuracy: 93.2% (IQR: 89-96%) - Median AUC-ROC: 0.91 (IQR: 0.87-0.94)\n- Median F1-score: 0.89 (IQR: 0.84-0.93)\n\n\n\n\n\n\nAlgorithm Evolution (2019-2024): • Deep Learning: 41% → 72% (+76%) • Explainable AI: +42% post-2021 • Federated Learning: +380% • Edge/TinyML: 27% of IoT studies\n\n\n\n\nAlgorithmic Fairness: 86% unassessed (ΔAUC=0.12 demographic gaps)\nOOD Generalization: 73% degrade ≥15% on new domains\nModel Drift: 91% lack monitoring (-22% accuracy/12mo)\nCausal Inference: &lt;5% use causal models\nLow-Resource: &lt;3% LMIC applications\n\n\n\n\n\nH₁: Hybrid DM-ML frameworks integrating causal discovery (NOTEARS algorithm) as priors for neural networks will achieve ≥18% higher F1-scores under out-of-distribution shifts vs. standard supervised learning. Test Protocol: Datasets: MIMIC-IV (health), NYC Taxi (transport), Rossmann Sales (retail) Metrics: F1_macro, AUCPR, calibration error Validation: 10-fold CV + temporal holdout Power: α=0.05, power=0.90 (n=10k/fold) Rationale: Causal graphs constrain spurious correlations, enhancing robustness to covariate/concept shift.\n\n\n\nDM/ML delivers production-grade performance across domains: Strengths: - Surpasses human experts (radiology: ML 0.94 vs human 0.88) - Scalable to petabyte-scale data - Real-time deployment proven Challenges: - Reproducibility crisis (23% open code) - Ethical deployment gaps - Production drift unaddressed Recommendations: 1. Mandate fairness audits 2. Standardize causal benchmarks\n3. Fund hybrid DM-ML research\n\n\n\nThis review of 92 studies confirms DM/ML transformation across six domains while exposing critical gaps in robustness and ethics. Causal-hybrid approaches offer the path forward. Total word count: 2,018\n\n\n\nAggarwal, C.C. Data Mining: The Textbook. Springer, 2015.\nChlingaryan, A. et al. “Crop yield prediction using machine learning.” Computers and Electronics in Agriculture, 2019.\nGulshan, V. et al. “Development and validation of a deep learning algorithm for detection of diabetic retinopathy.” JAMA, 2016.\nLessmann, S. et al. “Benchmarking state-of-the-art classification algorithms for credit scoring.” JORS, 2019.\nPurushotham, S. et al. “Benchmarking deep learning models on MIMIC-IV.” Nature Medicine, 2022.\nZheng, X. et al. “DAGs with NO TEARS.” NeurIPS, 2018. (Full 92-study bibliography available in supplementary materials)"
  },
  {
    "objectID": "km_sp2026/assignment.html#model-runs-raw-outputs",
    "href": "km_sp2026/assignment.html#model-runs-raw-outputs",
    "title": "Assignment 2: Prompt Exercise",
    "section": "",
    "text": "This structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n\n\n\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n\n\n\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability.\n\n\n\n\n\n\nThis systematic literature review examines the application of Data Mining (DM) and Machine Learning (ML) across various real-world domains over the past decade. By synthesizing findings from 45 selected studies, this review identifies key trends in healthcare, finance, and cybersecurity. The analysis reveals a significant shift towards Deep Learning (DL) techniques, although explainability remains a critical gap. A testable hypothesis regarding the trade-off between model complexity and interpretability in high-stakes domains is proposed.\n\n\n\nThe exponential growth of data has catalyzed the adoption of Data Mining (DM) and Machine Learning (ML) technologies across diverse sectors. From predictive analytics in healthcare to fraud detection in finance, these technologies are reshaping decision-making processes. This review aims to systematically analyze the state-of-the-art applications, focusing on methodology, impact, and prevailing challenges.\n\n\n\nThis review follows the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines.\n\n\nA comprehensive search was conducted on IEEE Xplore, ACM Digital Library, and PubMed using the search string: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\") AND (\"Application\" OR \"Real-world\") AND (\"Healthcare\" OR \"Finance\" OR \"Cybersecurity\").\n\n\n\nInclusion Criteria: - Peer-reviewed articles published between 2014 and 2024. - Studies focusing on practical, real-world implementations. - Articles written in English.\nExclusion Criteria: - Purely theoretical papers without empirical validation. - Survey papers (to avoid redundancy). - Non-peer-reviewed white papers.\n\n\n\nData was extracted based on: 1. Domain of Application 2. Algorithms Used 3. Dataset Scale and Type 4. Performance Metrics 5. Reported Challenges\n\n\n\n\n\n\nHealthcare remains the most prolific domain for ML applications. * Diagnostics: Convolutional Neural Networks (CNNs) have achieved parity with human experts in analyzing medical imaging (X-rays, MRIs). * Prognostics: DM techniques are widely used for predicting patient readmission rates and disease progression. * Key Insight: While accuracy is high, clinical adoption is hindered by the “black box” nature of advanced models.\n\n\n\nThe financial sector heavily utilizes DM for risk management and fraud detection. * Fraud Detection: Ensemble methods like Random Forest and Gradient Boosting Machines (GBM) are preferred for their robustness against imbalanced datasets. * Algorithmic Trading: Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are standard for time-series forecasting.\n\n\n\nWith the rise of cyber threats, ML has become integral to intrusion detection systems (IDS). * Anomaly Detection: Unsupervised learning techniques (e.g., K-Means, Autoencoders) are effective in identifying zero-day attacks. * Trend: There is a growing shift towards adversarial machine learning to robustness testing.\n\n\n\n\n\n\n\nShift to Deep Learning: A clear migration from traditional statistical methods (Regression, SVM) to Deep Learning architectures (CNN, Transformer models) across all domains.\nAutoML: Increasing use of Automated Machine Learning tools to democratize AI application for non-experts.\nEdge AI: Deployment of lightweight models on IoT devices, particularly in healthcare monitoring and industrial maintenance.\n\n\n\n\n\nExplainability (XAI): A significant gap exists between model performance and interpretability. In high-stakes domains like law and medicine, this lack of transparency is a barrier to trust and regulatory compliance.\nData Quality and Bias: Many real-world datasets suffer from bias, leading to unfair algorithmic outcomes. Standardization in data preprocessing is lacking.\nScalability: While models perform well in controlled environments, scalability issues often arise during full-scale deployment.\n\n\n\n\n\nBased on the identified gap in Explainable AI (XAI), we propose the following hypothesis:\nHypothesis: In high-stakes decision-making environments (e.g., medical diagnosis, loan approval), the integration of “human-in-the-loop” interactive explainability features will statistically significantly increase user trust and adoption rates compared to black-box models with higher raw accuracy.\nProposed Experiment: * Variables: Independent variable: Type of model interface (Black-box vs. XAI dashboard). Dependent variable: User trust score (Likert scale) and adoption rate. * Method: A/B testing with domain experts using a controlled dataset.\n\n\n\nThis review highlights the transformative power of DM and ML. While technical capabilities have advanced rapidly, the socio-technical challenges of trust, explainability, and bias remain the new frontier for research. Future work must bridge the gap between high-performance algorithms and human-interpretable insights.\n\n\n\n\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.\nEsteva, A., et al. (2017). Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639), 115-118.\nChandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58.\n\n\n\n\n\n\n\nThis systematic literature review examines applications of data mining (DM) and machine learning (ML) across real-world domains from 92 peer-reviewed studies (2019–2024). Following PRISMA guidelines, 1,856 records were screened, yielding high-quality empirical evidence. Key findings reveal deep learning (58%) and ensemble methods (32%) dominating healthcare, finance, transportation, agriculture, manufacturing, and retail, achieving median AUC=0.91 and accuracy=93%. Trends: explainable AI (+42%), federated learning (+380%), edge ML.\nGaps: fairness audits (14%), OOD generalization, model drift.\nHypothesis: Hybrid DM-ML with causal discovery improves OOD F1-scores by ≥18%. (Word count: 112)\n\n\n\nData mining extracts patterns from large datasets using clustering, association rules, and anomaly detection. Machine learning enables predictive modeling via supervised, unsupervised, and reinforcement learning paradigms. Real-world applications span healthcare diagnostics to financial fraud detection, generating economic value exceeding $13 trillion by 2030. Objectives: - Synthesize empirical applications across domains - Identify trends and methodological gaps\n- Propose testable research hypothesis\n\n\n\n\n\nDatabases (April 2024): Scopus, Web of Science, PubMed, IEEE Xplore, ACM DL.\nSearch string: (\"data mining\" OR \"machine learning\") AND (healthcare OR finance OR agriculture) AND (\"real world\" OR \"case study\") AND (2019:2024) Records: 1,856 → screened 1,428 → full-text 312 → included 92 (κ=0.89) ##### 2.2 Inclusion Criteria - Empirical studies with real-world datasets (≥50k instances)\n- Quantitative performance metrics (AUC, F1, accuracy) - Peer-reviewed journals/conferences (2019–2024) ##### 2.3 Quality Assessment Newcastle-Ottawa Scale (modified): High (55%), Moderate (37%), Low (8%)\n\n\n\n\n\n\n\n\n\nDomain\nStudies\nKey Algorithms\nMedian AUC\nExample\n\n\n\n\nHealthcare\n27\nCNN, LSTM\n0.94\nPneumonia detection (94%)\n\n\nFinance\n20\nXGBoost, GNN\n0.93\nFraud detection (99.8%)\n\n\nTransport\n15\nGCN, RL\n0.88\nTraffic forecasting\n\n\nAgriculture\n12\nU-Net, ViT\n0.91\nCrop yield prediction\n\n\nManufacturing\n11\nLSTM\n0.92\nPredictive maintenance\n\n\nRetail\n7\nGraphSAGE\n0.89\nRecommendations\n\n\n\n\n\n\nAggregated metrics (n=92): - Median accuracy: 93.2% (IQR: 89-96%) - Median AUC-ROC: 0.91 (IQR: 0.87-0.94)\n- Median F1-score: 0.89 (IQR: 0.84-0.93)\n\n\n\n\n\n\nAlgorithm Evolution (2019-2024): • Deep Learning: 41% → 72% (+76%) • Explainable AI: +42% post-2021 • Federated Learning: +380% • Edge/TinyML: 27% of IoT studies\n\n\n\n\nAlgorithmic Fairness: 86% unassessed (ΔAUC=0.12 demographic gaps)\nOOD Generalization: 73% degrade ≥15% on new domains\nModel Drift: 91% lack monitoring (-22% accuracy/12mo)\nCausal Inference: &lt;5% use causal models\nLow-Resource: &lt;3% LMIC applications\n\n\n\n\n\nH₁: Hybrid DM-ML frameworks integrating causal discovery (NOTEARS algorithm) as priors for neural networks will achieve ≥18% higher F1-scores under out-of-distribution shifts vs. standard supervised learning. Test Protocol: Datasets: MIMIC-IV (health), NYC Taxi (transport), Rossmann Sales (retail) Metrics: F1_macro, AUCPR, calibration error Validation: 10-fold CV + temporal holdout Power: α=0.05, power=0.90 (n=10k/fold) Rationale: Causal graphs constrain spurious correlations, enhancing robustness to covariate/concept shift.\n\n\n\nDM/ML delivers production-grade performance across domains: Strengths: - Surpasses human experts (radiology: ML 0.94 vs human 0.88) - Scalable to petabyte-scale data - Real-time deployment proven Challenges: - Reproducibility crisis (23% open code) - Ethical deployment gaps - Production drift unaddressed Recommendations: 1. Mandate fairness audits 2. Standardize causal benchmarks\n3. Fund hybrid DM-ML research\n\n\n\nThis review of 92 studies confirms DM/ML transformation across six domains while exposing critical gaps in robustness and ethics. Causal-hybrid approaches offer the path forward. Total word count: 2,018\n\n\n\nAggarwal, C.C. Data Mining: The Textbook. Springer, 2015.\nChlingaryan, A. et al. “Crop yield prediction using machine learning.” Computers and Electronics in Agriculture, 2019.\nGulshan, V. et al. “Development and validation of a deep learning algorithm for detection of diabetic retinopathy.” JAMA, 2016.\nLessmann, S. et al. “Benchmarking state-of-the-art classification algorithms for credit scoring.” JORS, 2019.\nPurushotham, S. et al. “Benchmarking deep learning models on MIMIC-IV.” Nature Medicine, 2022.\nZheng, X. et al. “DAGs with NO TEARS.” NeurIPS, 2018. (Full 92-study bibliography available in supplementary materials)"
  },
  {
    "objectID": "km_sp2026/assignment.html#structure-systematic-review-format",
    "href": "km_sp2026/assignment.html#structure-systematic-review-format",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.1 2.1 Structure (Systematic Review Format)",
    "text": "2.1 2.1 Structure (Systematic Review Format)\n\n2.1.1 ChatGPT\n\nClear SLR-like structure: Abstract → Introduction → Methodology → Domain findings → Trends → Gaps → Hypothesis → Conclusion.\nMethodology is conceptually complete (databases, inclusion/exclusion, PRISMA-style workflow, synthesis plan) but remains generic (no fixed time window; example search string only; no explicit screening counts).\n\n\n\n2.1.2 Copilot\n\nStrong SLR structure with PRISMA mention and clearly separated sections (methods/findings/trends/hypothesis/references).\nProvides an explicit search string and eligibility criteria; includes “data extraction” fields (good for systematic coding).\nMentions “45 selected studies” but does not show screening trace (counts or PRISMA flow). This is acceptable if framed as “example workflow,” but risky if presented as a factual result.\n\n\n\n2.1.3 Grok 3\n\nAppears highly “formal” (PRISMA, κ statistic, quality assessment scale, tables, performance synthesis).\nHowever, it contains many precise quantitative claims (records screened, included studies, κ, percentages, median AUC/accuracy) without verifiable evidence. For an assignment prompt output, these should be treated as unsubstantiated unless the model provides traceable sources.\n\nStructure takeaway: Copilot is the most “report-ready” and concise; ChatGPT is the most coherent and balanced; Grok 3 is highly structured but overconfident with unverifiable numbers."
  },
  {
    "objectID": "km_sp2026/assignment.html#synthesis-coverage-and-analytical-depth",
    "href": "km_sp2026/assignment.html#synthesis-coverage-and-analytical-depth",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.2 2.2 Synthesis (Coverage and Analytical Depth)",
    "text": "2.2 2.2 Synthesis (Coverage and Analytical Depth)\n\n2.2.1 ChatGPT\n\nBroad multi-domain synthesis (healthcare, finance, public policy, cybersecurity, education).\nStrong “cross-domain” logic: shared success conditions (decision context, data pipelines, evaluation beyond accuracy, human-in-the-loop, deployment monitoring).\n\n\n\n2.2.2 Copilot\n\nFocuses on three domains (healthcare/finance/cybersecurity), with clear bullet-point application summaries.\nSlightly less cross-domain meta-synthesis than ChatGPT, but the domain summaries are easy to read and academically styled.\n\n\n\n2.2.3 Grok 3\n\nCovers more domains and presents a comparative table.\nBut the synthesis depends heavily on quantitative performance summaries (median AUC, accuracy, domain-level metrics) that are not supported by sources; therefore, the analytic value is weakened by credibility concerns.\n\nSynthesis takeaway: ChatGPT provides the strongest cross-domain reasoning; Copilot provides concise, structured synthesis; Grok provides breadth but with credibility issues."
  },
  {
    "objectID": "km_sp2026/assignment.html#trends-and-research-gaps",
    "href": "km_sp2026/assignment.html#trends-and-research-gaps",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.3 2.3 Trends and Research Gaps",
    "text": "2.3 2.3 Trends and Research Gaps\n\n2.3.1 ChatGPT\n\nTrends are modern and detailed (foundation models, multimodal learning, privacy-preserving ML, causal ML, MLOps, robustness, explainability).\nGaps are specific and researchable (transportability, causal impact of deployment, fairness/harm metrics, operational interpretability, governance, ML security, long-term monitoring).\n\n\n\n2.3.2 Copilot\n\nTrends are relevant (deep learning shift, AutoML, edge AI).\nGaps cover core applied problems (XAI, data bias/quality, scalability).\nLess granular than ChatGPT, but still meaningful.\n\n\n\n2.3.3 Grok 3\n\nTrends/gaps include plausible topics (federated learning, OOD generalization, drift, fairness).\nHowever, it attaches precise percentages and effect sizes (e.g., “fairness audits 14%”, “OOD degrade ≥15%”) without sources—these should be rewritten as qualitative statements unless verified.\n\nTrends & gaps takeaway: ChatGPT is the most detailed and research-oriented; Copilot is solid but general; Grok is potentially insightful but numerically unreliable."
  },
  {
    "objectID": "km_sp2026/assignment.html#hypothesis-testable-and-relevant",
    "href": "km_sp2026/assignment.html#hypothesis-testable-and-relevant",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.4 2.4 Hypothesis (Testable and Relevant?)",
    "text": "2.4 2.4 Hypothesis (Testable and Relevant?)\n\n2.4.1 ChatGPT\n\nHypothesis about explainability increasing trust/adoption.\nClearly operationalized IV/DV and test design (A/B or experiment). Highly testable.\n\n\n\n2.4.2 Copilot\n\nSimilar hypothesis (human-in-the-loop explainability increases trust/adoption).\nTestable with IV/DV specified; good alignment with its identified gap (XAI).\n\n\n\n2.4.3 Grok 3\n\nHypothesis about causal-discovery priors improving OOD F1 by ≥18%.\nTestable in principle, but the “≥18%” threshold is an unsupported numeric claim; better phrased as “improves OOD performance” unless benchmarked.\n\nHypothesis takeaway: ChatGPT and Copilot propose the most defensible hypotheses; Grok’s is creative but needs removal of unsupported numeric target."
  },
  {
    "objectID": "km_sp2026/assignment.html#references-accuracy-check",
    "href": "km_sp2026/assignment.html#references-accuracy-check",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.5 2.5 References (Accuracy Check)",
    "text": "2.5 2.5 References (Accuracy Check)\n\n2.5.1 ChatGPT references\n\nNo explicit reference list was provided. This avoids fabricated citations but reduces academic verifiability.\n\n\n\n2.5.2 Copilot references (checked)\n\nLeCun, Bengio, & Hinton (2015), “Deep learning,” Nature 521:436–444 — Accurate. :contentReferenceoaicite:1\n\nEsteva et al. (2017), “Dermatologist-level classification of skin cancer…,” Nature 542 — Accurate. :contentReferenceoaicite:2\n\nChandola, Banerjee, & Kumar (2009), “Anomaly detection: A survey,” ACM Computing Surveys 41(3) — Accurate. :contentReferenceoaicite:3\n\nCopilot reference takeaway: citations are verifiable and appropriate.\n\n\n2.5.3 Grok 3 references (checked / flagged)\n\nAggarwal (2015), Data Mining: The Textbook (Springer) — Accurate. :contentReferenceoaicite:4\n\nChlingaryan et al. crop yield prediction — the commonly cited Chlingaryan review is 2018 (precision agriculture review), not clearly matching Grok’s “2019 crop yield prediction” citation. This should be treated as uncertain / needs correction. :contentReferenceoaicite:5\n\nLessmann et al. “Benchmarking state-of-the-art classification algorithms for credit scoring” — there is a well-known 2015 European Journal of Operational Research paper with this title; Grok’s “JORS 2019” style detail is likely inconsistent. Treat as needs correction. :contentReferenceoaicite:6\n\nPurushotham et al. “Benchmarking deep learning models on MIMIC-IV,” Nature Medicine 2022 — Not supported by verification; Purushotham’s benchmarking work is known in 2018 (clinical prediction tasks, MIMIC datasets) rather than “Nature Medicine 2022 MIMIC-IV” as stated. Flag as likely inaccurate unless replaced with a verified source. :contentReferenceoaicite:7\n\nGrok reference takeaway: mixed—some accurate, several require correction; numerical claims throughout should not be presented as factual without traceable sources."
  },
  {
    "objectID": "km_sp2026/assignment.html#summary-table-strengths-and-weaknesses",
    "href": "km_sp2026/assignment.html#summary-table-strengths-and-weaknesses",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.6 Summary Table (Strengths and Weaknesses)",
    "text": "2.6 Summary Table (Strengths and Weaknesses)\n\n2.6.1 Model | Strengths | Weaknesses / Risks | Best Contribution |\n|—|—|—|—| | ChatGPT | Strong cross-domain synthesis; detailed trends/gaps; clear hypothesis design | Methodology is more generic; lacks explicit references | Integrative synthesis + researchable gaps | | Copilot | Concise, report-ready structure; verifiable references; clear methods | Less cross-domain meta-synthesis; “45 studies” claim lacks trace | Clean structure + credible citations | | Grok 3 | Broad coverage; creative hypothesis; rich tables | Many unverifiable numeric claims; several references inconsistent | Interesting directions, but needs strict verification |"
  },
  {
    "objectID": "km_sp2026/assignment.html#step-2-conclusion-what-to-fix-in-step-3",
    "href": "km_sp2026/assignment.html#step-2-conclusion-what-to-fix-in-step-3",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.7 Step 2 Conclusion (What to fix in Step 3)",
    "text": "2.7 Step 2 Conclusion (What to fix in Step 3)\nBased on this analysis, the refined prompts in Step 3 should: 1. Force reproducible methodology (databases + Boolean query + eligibility + coding scheme). 2. Prohibit fabricated PRISMA counts or performance statistics unless sourced. 3. Require verifiable citations or explicitly label uncertain ones as “candidate references.” 4. Push for cross-domain synthesis (not only descriptive domain summaries)."
  },
  {
    "objectID": "km_sp2026/assignment.html#chatgpt-output",
    "href": "km_sp2026/assignment.html#chatgpt-output",
    "title": "Assignment 2: Prompt Exercise",
    "section": "3.1 ChatGPT output",
    "text": "3.1 ChatGPT output\n\n3.1.1 Abstract\nThis systematic literature review (SLR) synthesizes research on how data mining (DM) and machine learning (ML) are applied in three high-impact real-world domains—healthcare, finance, and education. The review summarizes common problem formulations (classification, risk prediction, anomaly detection, natural language processing, recommendation), dominant model families (linear/regularized models, tree-based ensembles, deep learning, and graph-based methods), typical data modalities (tabular, text, image, time series, graph), and evaluation practices. Across domains, the literature indicates recurring socio-technical constraints: distribution shift, data quality and missingness, fairness and accountability, privacy regulation, interpretability demands, and deployment frictions. Emerging trends include foundation models, multimodal learning, privacy-preserving computation, and MLOps standardization, while persistent gaps involve transportability/external validation, causal impact of deployment, domain-aligned interpretability, and secure/robust learning under adversarial settings. A bold, testable hypothesis is proposed linking explanation + uncertainty communication to adoption and performance outcomes in high-stakes decision workflows.\n\n\n\n3.1.2 1. Introduction\nThe proliferation of large-scale digital data has accelerated the adoption of DM and ML across sectors where decision-making is high-stakes and resource-constrained. DM traditionally emphasizes pattern discovery (e.g., clustering, association mining, anomaly detection) and descriptive insights, while ML emphasizes predictive and decision-oriented modeling under uncertainty. In practice, modern applied systems integrate both: feature engineering, supervised prediction, anomaly detection, text mining, and continuous monitoring.\nHealthcare, finance, and education share a common challenge: modeling decisions are embedded in institutional workflows, regulated environments, and heterogeneous populations. As a result, real-world performance depends not only on model accuracy but also on robustness to shift, interpretability for stakeholders, privacy constraints, and governance. This review aims to (i) summarize applications and methods, (ii) provide cross-domain synthesis and “fresh insights” about deployment tradeoffs, (iii) identify trends and gaps, and (iv) propose a testable hypothesis to advance future research.\n\n\n\n3.1.3 2. Methodology (Systematic Review Protocol)\n\n3.1.3.1 2.1 Research Questions\nRQ1: What are the predominant application tasks of DM/ML in healthcare, finance, and education, and what model families are most commonly used?\nRQ2: What constraints (data, evaluation, deployment, governance) shape model performance and real-world adoption across these domains?\n\n\n3.1.3.2 2.2 Search Strategy\nA structured search would typically be conducted in major digital libraries and indexing services such as: - IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (healthcare), and ERIC (education) (supplementary)."
  },
  {
    "objectID": "km_sp2026/assignment.html#copilot-output",
    "href": "km_sp2026/assignment.html#copilot-output",
    "title": "Assignment 2: Prompt Exercise",
    "section": "3.2 Copilot output",
    "text": "3.2 Copilot output\n\n3.2.1 Abstract\nThis systematic literature review synthesizes the state-of-the-art applications of Data Mining (DM) and Machine Learning (ML) across three critical domains: Healthcare, Finance, and Education. By analyzing 60 peer-reviewed studies published between 2015 and 2025, this review identifies a convergence of techniques—specifically Deep Learning and Natural Language Processing—while highlighting domain-specific challenges such as interpretability in healthcare, volatility modeling in finance, and privacy in educational data mining. The review reveals a critical gap in cross-domain transfer learning and proposes a bold, testable hypothesis regarding the efficacy of “Federated Transfer Learning” in data-scarce environments.\n\n\n3.2.2 1. Introduction\nThe ubiquity of big data has catalyzed a paradigm shift in decision-making processes. Machine Learning (ML) and Data Mining (DM) have evolved from experimental tools to foundational infrastructure. In healthcare, they drive precision medicine; in finance, they underpin algorithmic trading and fraud detection; and in education, they power adaptive learning platforms. This review aims to dissect the methodological commonalities and divergences across these sectors to inform future interdisciplinary research.\n\n\n3.2.3 2. Methodology\nThis review adheres to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to ensure rigor and replicability.\n\n3.2.3.1 2.1 Search Strategy\nA systematic search was executed across IEEE Xplore, ACM Digital Library, PubMed, and ERIC (Education Resources Information Center).\nSearch String: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\" OR \"Neural Networks\") AND (\"Application\" OR \"Case Study\") AND (\"Healthcare\" OR \"Finance\" OR \"Education\" OR \"Learning Analytics\")\n\n\n3.2.3.2 2.2 Inclusion and Exclusion Criteria\n\nInclusion: Peer-reviewed journal articles and high-impact conference proceedings (2015–2025); empirical studies with real-world datasets.\nExclusion: Pre-prints, non-English publications, and pure review papers (to avoid tertiary sourcing).\n\n\n\n3.2.3.3 2.3 Data Extraction & Analysis\nStudies were coded based on: (1) Domain, (2) Problem Type (Classification, Regression, Clustering), (3) Algorithm Family, (4) Dataset Size, and (5) Evaluation Metrics.\n\n\n\n3.2.4 3. Synthesis of Key Findings\n\n3.2.4.1 3.1 Healthcare: From Diagnostics to Prognostics\nThe healthcare sector exhibits the highest adoption of Deep Learning, particularly Convolutional Neural Networks (CNNs) for medical imaging. * Key Finding: ML models for diagnostic imaging (e.g., detecting diabetic retinopathy) have achieved sensitivity and specificity rates exceeding 95%, often outperforming human radiologists in controlled settings. * Methodology Trend: A shift from Support Vector Machines (SVM) to ensemble methods (Random Forest, XGBoost) for Electronic Health Record (EHR) analysis due to their handling of categorical variables and missing data.\n\n\n3.2.4.2 3.2 Finance: Risk, Fraud, and High-Frequency Trading\nFinancial applications prioritize speed and interpretability (for regulatory compliance). * Key Finding: Anomaly detection algorithms (Isolation Forests, Autoencoders) are the standard for credit card fraud detection, reducing false positives by up to 30% compared to rule-based systems. * Methodology Trend: Long Short-Term Memory (LSTM) networks dominate time-series forecasting for stock prices, though Transformer models (e.g., BERT for financial sentiment analysis) are emerging as powerful tools for processing unstructured market news.\n\n\n3.2.4.3 3.3 Education: The Rise of Learning Analytics\nEducational Data Mining (EDM) focuses on predicting student performance and retention. * Key Finding: Predictive models using student interaction logs (LMS data) can identify “at-risk” students as early as the third week of a semester with 85% accuracy. * Methodology Trend: Knowledge Tracing (KT) has evolved from Bayesian Knowledge Tracing (BKT) to Deep Knowledge Tracing (DKT), capturing complex temporal dependencies in student learning curves.\n\n\n\n3.2.5 4. Trends and Gaps\n\n3.2.5.1 4.1 Cross-Cutting Trends\n\nExplainable AI (XAI): Across all three domains, the “black box” nature of Deep Learning is a primary barrier to adoption. Techniques like SHAP (SHapley Additive exPlanations) and LIME are increasingly standard in published research.\nAutoML and Democratization: Tools that automate hyperparameter tuning and model selection are enabling domain experts (doctors, educators) to build models without deep technical expertise.\n\n\n\n3.2.5.2 4.2 Critical Gaps\n\nData Privacy and Ethics: While Differential Privacy is discussed theoretically, practical implementations in shared datasets (especially in Education and Healthcare) remain scarce.\nSiloed Innovation: Techniques successful in one domain (e.g., sequence modeling in NLP) are slow to permeate others (e.g., patient trajectory modeling), indicating a lack of cross-pollination.\nLack of Longitudinal Studies: Most studies report static performance metrics; few evaluate the long-term impact of algorithmic interventions on human outcomes.\n\n\n\n\n3.2.6 5. Proposed Hypothesis\nBased on the synthesis of findings, specifically the struggle with data scarcity in specialized sub-domains (e.g., rare diseases, specific learning disabilities), we propose the following Federated Transfer Learning Hypothesis:\n\nHypothesis: A Federated Transfer Learning (FTL) framework, pre-trained on a generic, large-scale dataset (e.g., general EHRs) and fine-tuned on decentralized, privacy-preserved institutional data (e.g., specific rare disease registries), will achieve a statistically significant improvement (p &lt; 0.05) in F1-score compared to locally trained models, without compromising data privacy standards (measured by epsilon-differential privacy).\n\nExperimental Design for Validation: 1. Control Group: Independent LSTM models trained on isolated hospital datasets for sepsis prediction. 2. Experimental Group: A global LSTM model pre-trained on public MIMIC-III data, then fine-tuned via Federated Averaging across the isolated hospitals. 3. Metrics: Compare AUC-ROC, F1-score, and communication overhead.\n\n\n3.2.7 6. Conclusion\nThe convergence of DM and ML in Healthcare, Finance, and Education is driving unprecedented efficiency and personalization. However, the maturation of these fields depends not on finding more complex algorithms, but on solving the “last mile” problems: interpretability, ethical data governance, and rigorous validation in dynamic, real-world environments. Future research must pivot from maximizing accuracy on static benchmarks to optimizing human-AI collaboration.\n\n\n3.2.8 References\n(Placeholder for BibTeX references)\n\nRajkomar, A., et al. (2018). Scalable and accurate deep learning with electronic health records. NPJ Digital Medicine.\nDixon, M. F., Halperin, I., & Bilokon, P. (2020). Machine Learning in Finance: From Theory to Practice. Springer.\nBaker, R. S., & Inventado, P. S. (2014). Educational data mining and learning analytics. Learning Analytics."
  },
  {
    "objectID": "km_sp2026/assignment.html#grok-3-output",
    "href": "km_sp2026/assignment.html#grok-3-output",
    "title": "Assignment 2: Prompt Exercise",
    "section": "3.3 Grok 3 output",
    "text": "3.3 Grok 3 output\n\n3.3.1 Executive Summary\nThis systematic review analyzes 108 empirical studies (2018-2024) across healthcare (42%), finance (35%), and education (23%). Using PRISMA 2020 methodology: Performance: AUC 0.92, F1 0.89\nTechniques: Deep learning 61%, Ensembles 28%\nTrends: XAI +350%, Federated +420%\nGaps: Fairness 11%, Causal &lt;4% Hypothesis: Multi-task causal DM-ML frameworks outperform single-task models by ≥22% in cross-domain transfer for minority subpopulations.\n(128 words) ### 1. Introduction Healthcare produces 2.5 quintillion bytes daily from EHRs, imaging, wearables. Finance processes $6.6T transactions daily. Education platforms serve 1.7B learners. Data mining (clustering, rules, anomalies) and machine learning (supervised/unsupervised/reinforcement) unlock insights. Research Questions: 1. Dominant DM/ML methods per domain? 2. Cross-domain performance patterns? 3. Trends and critical gaps? 4. Testable hypothesis from synthesis?\n\n\n3.3.2 2. Methodology\n\n3.3.2.1 2.1 PRISMA Protocol\nSearch: October 15, 2024 across Scopus (847), PubMed (392), Web of Science (285), IEEE (176), ERIC (89). Query: (“data mining” OR “machine learning”) AND (healthcare OR finance OR education) AND (“real world” OR “case study”) AND (2018:2024)\nFlow: 1,836 → screened 1,424 → full-text 289 → included 108 (deduped 412) #### 2.2 Quality Assessment | Domain | Selection Bias | Performance Bias | Applicability | |——–|—————-|——————|—————| | Healthcare | Low | Low | Moderate | | Finance | Low | Moderate | Low | | Education | Moderate | High | High |\n\n\n\n3.3.3 3. Domain Findings\n\n3.3.3.1 3.1 Healthcare (n=45)\n\n\n\nApplication\nAlgorithm\nDataset\nPerformance\n\n\n\n\nDisease Prediction\nCNN-LSTM\nMIMIC-IV\nAUC 0.94\n\n\nReadmission\nXGBoost\nUCI Heart\nF1 0.91\n\n\nDrug Discovery\nGraph NNs\nPubChem\nP@10 0.88\n\n\nSepsis\nGRU\neICU\n7h lead time\n\n\n\nInsight: Multimodal fusion +17% AUC vs unimodal.\n\n\n3.3.3.2 3.2 Finance (n=38)\n\nFraud: Isolation Forest, Recall 99.7% (2.4B transactions)\nCredit: LightGBM, KS 0.65 (15M loans)\nTrading: Transformer+RL, Sharpe 2.1\n\n\n\n3.3.3.3 3.3 Education (n=25)\n\nDropout prediction: LSTM AUC 0.89 (1M learners)\nPersonalized paths: Bandits +15% completion\nPlagiarism: BERT F1 0.93\n\n\n\n\n3.3.4 4. Cross-Model Collaboration (Synthesis)\n\n3.3.4.1 4.1 What I retained from each model (best elements)\nTo produce a final, academically sound review, I integrated the strongest elements from each model while filtering out unverifiable claims.\n\nFrom ChatGPT (strength: cross-domain synthesis and researchable gaps)\n\nKept the cross-domain synthesis logic (shared deployment constraints across domains).\nKept the richer and more current set of trends and gaps (e.g., MLOps, robustness, privacy-preserving ML, causal ML).\n\nFrom Copilot (strength: replicable methodology template and concise structure)\n\nKept the clearer “protocol-like” structure for Methods (databases, search string, eligibility criteria, and coding fields).\nAdopted its concise domain write-up style (bullets for tasks, model families, data modalities, metrics).\n\nFrom Grok 3 (strength: creative, forward-looking hypothesis framing)\n\nKept the idea of a “bolder” hypothesis that pushes beyond descriptive synthesis.\nDid not retain Grok 3’s numeric PRISMA counts, percentages, performance medians, or global economic-value claims because they were not verifiable from the prompt context.\n\n\n\n\n3.3.4.2 4.2 What I removed or constrained (quality control rules)\nAcross Copilot and Grok 3, the outputs included precise quantitative claims (e.g., number of studies screened, included studies, AUC/accuracy medians, percentage growth). Because I did not conduct an actual database search and did not document a PRISMA flow, these claims were treated as unsubstantiated and excluded from the synthesis.\nTo ensure academic integrity, the final synthesis must: 1. Avoid fabricated PRISMA counts and performance numbers unless explicitly supported by traceable sources. 2. Use verifiable references; if uncertain, label as “candidate reference.” 3. Emphasize cross-domain mechanisms (why deployment succeeds/fails), not just domain-by-domain listing.\n\n\n3.3.4.3 4.3 Synthesis Prompt for My Preferred Model (ChatGPT)\n\n\n\n3.3.5 Applications of Data Mining and Machine Learning in Real-World Domains: A Structured Systematic Literature Review\n\n3.3.5.1 Abstract\nThis structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n3.3.5.2 1. Introduction\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n3.3.5.3 2. Methodology (Structured SLR Approach)\n\n3.3.5.3.1 2.1 Search Strategy\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n3.3.5.3.2 2.2 Inclusion and Exclusion Criteria\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n3.3.5.3.3 2.3 Screening and Study Selection\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n3.3.5.3.4 2.4 Synthesis Approach\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n3.3.5.4 3. Findings by Domain (Applications and Key Patterns)\n\n3.3.5.4.1 3.1 Healthcare\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n3.3.5.4.2 3.2 Finance (Fraud, Risk, Trading, Credit)\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n3.3.5.4.3 3.3 Public Policy and Government Analytics\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n3.3.5.4.4 3.4 Cybersecurity\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n3.3.5.4.5 3.5 Education (Learning Analytics)\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n3.3.5.5 4. Cross-Domain Synthesis: What Works and Why\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n3.3.5.6 5. Emerging Trends (≥5)\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n3.3.5.7 6. Research Gaps (≥5)\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n3.3.5.8 7. Proposed Testable Hypothesis\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n3.3.5.8.1 Operationalization\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n3.3.5.9 8. Conclusion\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability."
  },
  {
    "objectID": "km_sp2026/assignment.html#how-did-each-model-approach-the-systematic-review-differently",
    "href": "km_sp2026/assignment.html#how-did-each-model-approach-the-systematic-review-differently",
    "title": "Assignment 2: Prompt Exercise",
    "section": "4.1 How did each model approach the systematic review differently?",
    "text": "4.1 How did each model approach the systematic review differently?\n\n4.1.1 ChatGPT\nChatGPT approached the task as a cross-domain conceptual synthesis. It emphasized (1) a clean SLR-like structure, (2) consistent domain-by-domain summaries (tasks, model families, data, evaluation, limitations), and (3) a strong cross-domain “what works and why” section. Its methodology description was credible but intentionally conservative—describing how an SLR should be done rather than asserting specific PRISMA counts or performance statistics.\n\n\n4.1.2 Copilot\nCopilot focused on producing a report-ready template with clear headings and a direct PRISMA framing. It typically excelled at concise structuring (methods → findings → trends/gaps → hypothesis) and gave concrete components such as a search string and coding fields. However, it tended to state specific scope claims (e.g., “X studies analyzed,” “2015–2025”) without showing a traceable screening log, so those details need user verification before being treated as factual.\n\n\n4.1.3 Grok 3\nGrok 3 prioritized a high-confidence, metrics-driven narrative. It presented a very “scientific-looking” review with detailed counts, percentages, pooled metrics, and strongly quantified trends and effects. While this style can look impressive, it introduced the highest risk of unverifiable or fabricated quantitative claims when the prompt did not provide underlying data. In my workflow, Grok 3 was most useful for generating bold hypotheses and highlighting possible frontier directions—but its numbers required strict filtering."
  },
  {
    "objectID": "km_sp2026/assignment.html#which-prompt-refinements-yielded-the-best-results-for-each-model",
    "href": "km_sp2026/assignment.html#which-prompt-refinements-yielded-the-best-results-for-each-model",
    "title": "Assignment 2: Prompt Exercise",
    "section": "4.2 Which prompt refinements yielded the best results for each model?",
    "text": "4.2 Which prompt refinements yielded the best results for each model?\n\n4.2.1 For ChatGPT\nFor ChatGPT, the most effective refinements were: - Forcing a reproducible Methods protocol (databases, one Boolean query, explicit inclusion/exclusion criteria, coding framework). - Requiring ≥5 trends and ≥5 gaps as researchable statements, which improved specificity. - Adding an integrity rule (“no fabricated PRISMA counts or performance numbers”) strengthened academic defensibility.\n\n\n4.2.2 For Copilot\nFor Copilot, the most effective refinements were: - Enforcing fixed headings and a “must-follow” outline (RQs → Methods → Findings → Trends/Gaps → Hypothesis → References). - Explicitly instructing: “If counts are unknown, say ‘not available’”, which reduces unsupported claims. - Requiring a coding framework (domain/task/modality/model/metric/deployment/risks) improved systematic clarity.\n\n\n4.2.3 For Grok 3\nFor Grok 3, the most effective refinements were: - Adding strict constraints: no numeric screening counts, no pooled performance metrics, no growth percentages unless cited. - Requiring that uncertain citations be labeled “candidate references” rather than asserted as true. - Asking for “fresh insights” as tradeoffs/tensions (accuracy vs interpretability, privacy vs utility, robustness vs performance) instead of numeric-heavy summaries."
  },
  {
    "objectID": "km_sp2026/assignment.html#what-did-you-learn-about-leveraging-ai-for-structured-academic-reviews",
    "href": "km_sp2026/assignment.html#what-did-you-learn-about-leveraging-ai-for-structured-academic-reviews",
    "title": "Assignment 2: Prompt Exercise",
    "section": "4.3 What did you learn about leveraging AI for structured academic reviews?",
    "text": "4.3 What did you learn about leveraging AI for structured academic reviews?\n\nAI is strongest at structure and synthesis, not at unverifiable specifics.\nThe models can reliably produce coherent organization (SLR headings), domain taxonomies, and cross-domain themes. But unless the user provides the evidence base (search results, screened papers), AI may generate overly specific numbers (PRISMA counts, pooled AUC) that should not be treated as factual.\nPrompting must operationalize rigor.\nThe best results came from prompts that required: explicit databases, a reproducible Boolean query, eligibility criteria, a screening workflow description, and a coding framework. These constraints transform “general summaries” into a workflow-aligned SLR draft.\nIntegrity constraints are essential for academic use.\nAdding rules like “do not fabricate counts or performance metrics” and “label uncertain citations as candidate references” greatly improved reliability. This also clarified which parts of the output are safe to publish in a course website.\nCross-model collaboration works best when each model is assigned a role.\nIn synthesis, I treated ChatGPT as the main integrator for cross-domain reasoning, Copilot as a structure/methods template engine, and Grok 3 as an idea generator for bold hypotheses and emerging directions—while filtering out unsupported quantitative claims.\n\nOverall, the process showed that AI can accelerate academic drafting and conceptual synthesis, but the user must impose methodological discipline and verification rules to produce an academically credible systematic review."
  },
  {
    "objectID": "km_sp2026/assignment.html#model-runs-raw-outputs-1",
    "href": "km_sp2026/assignment.html#model-runs-raw-outputs-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "5.1 Model Runs (Raw Outputs)",
    "text": "5.1 Model Runs (Raw Outputs)\n\n5.1.1 ChatGPT output (raw)\n\n5.1.1.1 Applications of Data Mining and Machine Learning in Real-World Domains: A Structured Systematic Literature Review\n\n\n5.1.1.2 Abstract\nThis structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n5.1.1.3 1. Introduction\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n5.1.1.4 2. Methodology (Structured SLR Approach)\n\n5.1.1.4.1 2.1 Search Strategy\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n5.1.1.4.2 2.2 Inclusion and Exclusion Criteria\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n5.1.1.4.3 2.3 Screening and Study Selection\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n5.1.1.4.4 2.4 Synthesis Approach\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n5.1.1.5 3. Findings by Domain (Applications and Key Patterns)\n\n5.1.1.5.1 3.1 Healthcare\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n5.1.1.5.2 3.2 Finance (Fraud, Risk, Trading, Credit)\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n5.1.1.5.3 3.3 Public Policy and Government Analytics\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n5.1.1.5.4 3.4 Cybersecurity\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n5.1.1.5.5 3.5 Education (Learning Analytics)\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n5.1.1.6 4. Cross-Domain Synthesis: What Works and Why\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n5.1.1.7 5. Emerging Trends (≥5)\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n5.1.1.8 6. Research Gaps (≥5)\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n5.1.1.9 7. Proposed Testable Hypothesis\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n5.1.1.9.1 Operationalization\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n5.1.1.10 8. Conclusion\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability.\n\n\n\n5.1.2 Copilot output (raw)\n\n5.1.2.1 Abstract\nThis systematic literature review examines the application of Data Mining (DM) and Machine Learning (ML) across various real-world domains over the past decade. By synthesizing findings from 45 selected studies, this review identifies key trends in healthcare, finance, and cybersecurity. The analysis reveals a significant shift towards Deep Learning (DL) techniques, although explainability remains a critical gap. A testable hypothesis regarding the trade-off between model complexity and interpretability in high-stakes domains is proposed.\n\n\n5.1.2.2 1. Introduction\nThe exponential growth of data has catalyzed the adoption of Data Mining (DM) and Machine Learning (ML) technologies across diverse sectors. From predictive analytics in healthcare to fraud detection in finance, these technologies are reshaping decision-making processes. This review aims to systematically analyze the state-of-the-art applications, focusing on methodology, impact, and prevailing challenges.\n\n\n5.1.2.3 2. Methodology\nThis review follows the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines.\n\n5.1.2.3.1 2.1 Search Strategy\nA comprehensive search was conducted on IEEE Xplore, ACM Digital Library, and PubMed using the search string: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\") AND (\"Application\" OR \"Real-world\") AND (\"Healthcare\" OR \"Finance\" OR \"Cybersecurity\").\n\n\n5.1.2.3.2 2.2 Inclusion and Exclusion Criteria\nInclusion Criteria: - Peer-reviewed articles published between 2014 and 2024. - Studies focusing on practical, real-world implementations. - Articles written in English.\nExclusion Criteria: - Purely theoretical papers without empirical validation. - Survey papers (to avoid redundancy). - Non-peer-reviewed white papers.\n\n\n5.1.2.3.3 2.3 Data Extraction\nData was extracted based on: 1. Domain of Application 2. Algorithms Used 3. Dataset Scale and Type 4. Performance Metrics 5. Reported Challenges\n\n\n\n5.1.2.4 3. Synthesis of Key Findings\n\n5.1.2.4.1 3.1 Healthcare\nHealthcare remains the most prolific domain for ML applications. * Diagnostics: Convolutional Neural Networks (CNNs) have achieved parity with human experts in analyzing medical imaging (X-rays, MRIs). * Prognostics: DM techniques are widely used for predicting patient readmission rates and disease progression. * Key Insight: While accuracy is high, clinical adoption is hindered by the “black box” nature of advanced models.\n\n\n5.1.2.4.2 3.2 Finance\nThe financial sector heavily utilizes DM for risk management and fraud detection. * Fraud Detection: Ensemble methods like Random Forest and Gradient Boosting Machines (GBM) are preferred for their robustness against imbalanced datasets. * Algorithmic Trading: Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are standard for time-series forecasting.\n\n\n5.1.2.4.3 3.3 Cybersecurity\nWith the rise of cyber threats, ML has become integral to intrusion detection systems (IDS). * Anomaly Detection: Unsupervised learning techniques (e.g., K-Means, Autoencoders) are effective in identifying zero-day attacks. * Trend: There is a growing shift towards adversarial machine learning to robustness testing.\n\n\n\n5.1.2.5 4. Trends and Gaps\n\n5.1.2.5.1 4.1 Emerging Trends\n\nShift to Deep Learning: A clear migration from traditional statistical methods (Regression, SVM) to Deep Learning architectures (CNN, Transformer models) across all domains.\nAutoML: Increasing use of Automated Machine Learning tools to democratize AI application for non-experts.\nEdge AI: Deployment of lightweight models on IoT devices, particularly in healthcare monitoring and industrial maintenance.\n\n\n\n5.1.2.5.2 4.2 Critical Gaps\n\nExplainability (XAI): A significant gap exists between model performance and interpretability. In high-stakes domains like law and medicine, this lack of transparency is a barrier to trust and regulatory compliance.\nData Quality and Bias: Many real-world datasets suffer from bias, leading to unfair algorithmic outcomes. Standardization in data preprocessing is lacking.\nScalability: While models perform well in controlled environments, scalability issues often arise during full-scale deployment.\n\n\n\n\n5.1.2.6 5. Proposed Testable Hypothesis\nBased on the identified gap in Explainable AI (XAI), we propose the following hypothesis:\nHypothesis: In high-stakes decision-making environments (e.g., medical diagnosis, loan approval), the integration of “human-in-the-loop” interactive explainability features will statistically significantly increase user trust and adoption rates compared to black-box models with higher raw accuracy.\nProposed Experiment: * Variables: Independent variable: Type of model interface (Black-box vs. XAI dashboard). Dependent variable: User trust score (Likert scale) and adoption rate. * Method: A/B testing with domain experts using a controlled dataset.\n\n\n5.1.2.7 6. Conclusion\nThis review highlights the transformative power of DM and ML. While technical capabilities have advanced rapidly, the socio-technical challenges of trust, explainability, and bias remain the new frontier for research. Future work must bridge the gap between high-performance algorithms and human-interpretable insights.\n\n\n5.1.2.8 References\n\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.\nEsteva, A., et al. (2017). Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639), 115-118.\nChandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58.\n\n\n\n\n5.1.3 Grok 3 output (raw)\n\n5.1.3.1 Abstract\nThis systematic literature review examines applications of data mining (DM) and machine learning (ML) across real-world domains from 92 peer-reviewed studies (2019–2024). Following PRISMA guidelines, 1,856 records were screened, yielding high-quality empirical evidence. Key findings reveal deep learning (58%) and ensemble methods (32%) dominating healthcare, finance, transportation, agriculture, manufacturing, and retail, achieving median AUC=0.91 and accuracy=93%. Trends: explainable AI (+42%), federated learning (+380%), edge ML.\nGaps: fairness audits (14%), OOD generalization, model drift.\nHypothesis: Hybrid DM-ML with causal discovery improves OOD F1-scores by ≥18%. (Word count: 112)\n\n\n5.1.3.2 1. Introduction\nData mining extracts patterns from large datasets using clustering, association rules, and anomaly detection. Machine learning enables predictive modeling via supervised, unsupervised, and reinforcement learning paradigms. Real-world applications span healthcare diagnostics to financial fraud detection, generating economic value exceeding $13 trillion by 2030. Objectives: - Synthesize empirical applications across domains - Identify trends and methodological gaps\n- Propose testable research hypothesis\n\n\n5.1.3.3 2. Methodology\n\n5.1.3.3.1 2.1 Search Strategy\nDatabases (April 2024): Scopus, Web of Science, PubMed, IEEE Xplore, ACM DL.\nSearch string: (\"data mining\" OR \"machine learning\") AND (healthcare OR finance OR agriculture) AND (\"real world\" OR \"case study\") AND (2019:2024) Records: 1,856 → screened 1,428 → full-text 312 → included 92 (κ=0.89) ##### 2.2 Inclusion Criteria - Empirical studies with real-world datasets (≥50k instances)\n- Quantitative performance metrics (AUC, F1, accuracy) - Peer-reviewed journals/conferences (2019–2024) ##### 2.3 Quality Assessment Newcastle-Ottawa Scale (modified): High (55%), Moderate (37%), Low (8%)\n\n\n\n5.1.3.4 3. Key Findings\n\n5.1.3.4.1 3.1 Domain Applications\n\n\n\nDomain\nStudies\nKey Algorithms\nMedian AUC\nExample\n\n\n\n\nHealthcare\n27\nCNN, LSTM\n0.94\nPneumonia detection (94%)\n\n\nFinance\n20\nXGBoost, GNN\n0.93\nFraud detection (99.8%)\n\n\nTransport\n15\nGCN, RL\n0.88\nTraffic forecasting\n\n\nAgriculture\n12\nU-Net, ViT\n0.91\nCrop yield prediction\n\n\nManufacturing\n11\nLSTM\n0.92\nPredictive maintenance\n\n\nRetail\n7\nGraphSAGE\n0.89\nRecommendations\n\n\n\n\n\n5.1.3.4.2 3.2 Performance Synthesis\nAggregated metrics (n=92): - Median accuracy: 93.2% (IQR: 89-96%) - Median AUC-ROC: 0.91 (IQR: 0.87-0.94)\n- Median F1-score: 0.89 (IQR: 0.84-0.93)\n\n\n\n5.1.3.5 4. Trends and Gaps\n\n5.1.3.5.1 4.1 Trends\nAlgorithm Evolution (2019-2024): • Deep Learning: 41% → 72% (+76%) • Explainable AI: +42% post-2021 • Federated Learning: +380% • Edge/TinyML: 27% of IoT studies\n\n\n5.1.3.5.2 4.2 Research Gaps\n\nAlgorithmic Fairness: 86% unassessed (ΔAUC=0.12 demographic gaps)\nOOD Generalization: 73% degrade ≥15% on new domains\nModel Drift: 91% lack monitoring (-22% accuracy/12mo)\nCausal Inference: &lt;5% use causal models\nLow-Resource: &lt;3% LMIC applications\n\n\n\n\n5.1.3.6 5. Testable Hypothesis\nH₁: Hybrid DM-ML frameworks integrating causal discovery (NOTEARS algorithm) as priors for neural networks will achieve ≥18% higher F1-scores under out-of-distribution shifts vs. standard supervised learning. Test Protocol: Datasets: MIMIC-IV (health), NYC Taxi (transport), Rossmann Sales (retail) Metrics: F1_macro, AUCPR, calibration error Validation: 10-fold CV + temporal holdout Power: α=0.05, power=0.90 (n=10k/fold) Rationale: Causal graphs constrain spurious correlations, enhancing robustness to covariate/concept shift.\n\n\n5.1.3.7 6. Discussion\nDM/ML delivers production-grade performance across domains: Strengths: - Surpasses human experts (radiology: ML 0.94 vs human 0.88) - Scalable to petabyte-scale data - Real-time deployment proven Challenges: - Reproducibility crisis (23% open code) - Ethical deployment gaps - Production drift unaddressed Recommendations: 1. Mandate fairness audits 2. Standardize causal benchmarks\n3. Fund hybrid DM-ML research\n\n\n5.1.3.8 7. Conclusion\nThis review of 92 studies confirms DM/ML transformation across six domains while exposing critical gaps in robustness and ethics. Causal-hybrid approaches offer the path forward. Total word count: 2,018\n\n5.1.3.8.1 References\n\nAggarwal, C.C. Data Mining: The Textbook. Springer, 2015.\nChlingaryan, A. et al. “Crop yield prediction using machine learning.” Computers and Electronics in Agriculture, 2019.\nGulshan, V. et al. “Development and validation of a deep learning algorithm for detection of diabetic retinopathy.” JAMA, 2016.\nLessmann, S. et al. “Benchmarking state-of-the-art classification algorithms for credit scoring.” JORS, 2019.\nPurushotham, S. et al. “Benchmarking deep learning models on MIMIC-IV.” Nature Medicine, 2022.\nZheng, X. et al. “DAGs with NO TEARS.” NeurIPS, 2018. (Full 92-study bibliography available in supplementary materials)"
  },
  {
    "objectID": "km_sp2026/assignment.html#structure-systematic-review-format-1",
    "href": "km_sp2026/assignment.html#structure-systematic-review-format-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "6.1 2.1 Structure (Systematic Review Format)",
    "text": "6.1 2.1 Structure (Systematic Review Format)\n\n6.1.1 ChatGPT\n\nClear SLR-like structure: Abstract → Introduction → Methodology → Domain findings → Trends → Gaps → Hypothesis → Conclusion.\nMethodology is conceptually complete (databases, inclusion/exclusion, PRISMA-style workflow, synthesis plan) but remains generic (no fixed time window; example search string only; no explicit screening counts).\n\n\n\n6.1.2 Copilot\n\nStrong SLR structure with PRISMA mention and clearly separated sections (methods/findings/trends/hypothesis/references).\nProvides an explicit search string and eligibility criteria; includes “data extraction” fields (good for systematic coding).\nMentions “45 selected studies” but does not show screening trace (counts or PRISMA flow). This is acceptable if framed as “example workflow,” but risky if presented as a factual result.\n\n\n\n6.1.3 Grok 3\n\nAppears highly “formal” (PRISMA, κ statistic, quality assessment scale, tables, performance synthesis).\nHowever, it contains many precise quantitative claims (records screened, included studies, κ, percentages, median AUC/accuracy) without verifiable evidence. For an assignment prompt output, these should be treated as unsubstantiated unless the model provides traceable sources.\n\nStructure takeaway: Copilot is the most “report-ready” and concise; ChatGPT is the most coherent and balanced; Grok 3 is highly structured but overconfident with unverifiable numbers."
  },
  {
    "objectID": "km_sp2026/assignment.html#synthesis-coverage-and-analytical-depth-1",
    "href": "km_sp2026/assignment.html#synthesis-coverage-and-analytical-depth-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "6.2 2.2 Synthesis (Coverage and Analytical Depth)",
    "text": "6.2 2.2 Synthesis (Coverage and Analytical Depth)\n\n6.2.1 ChatGPT\n\nBroad multi-domain synthesis (healthcare, finance, public policy, cybersecurity, education).\nStrong “cross-domain” logic: shared success conditions (decision context, data pipelines, evaluation beyond accuracy, human-in-the-loop, deployment monitoring).\n\n\n\n6.2.2 Copilot\n\nFocuses on three domains (healthcare/finance/cybersecurity), with clear bullet-point application summaries.\nSlightly less cross-domain meta-synthesis than ChatGPT, but the domain summaries are easy to read and academically styled.\n\n\n\n6.2.3 Grok 3\n\nCovers more domains and presents a comparative table.\nBut the synthesis depends heavily on quantitative performance summaries (median AUC, accuracy, domain-level metrics) that are not supported by sources; therefore, the analytic value is weakened by credibility concerns.\n\nSynthesis takeaway: ChatGPT provides the strongest cross-domain reasoning; Copilot provides concise, structured synthesis; Grok provides breadth but with credibility issues."
  },
  {
    "objectID": "km_sp2026/assignment.html#trends-and-research-gaps-1",
    "href": "km_sp2026/assignment.html#trends-and-research-gaps-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "6.3 2.3 Trends and Research Gaps",
    "text": "6.3 2.3 Trends and Research Gaps\n\n6.3.1 ChatGPT\n\nTrends are modern and detailed (foundation models, multimodal learning, privacy-preserving ML, causal ML, MLOps, robustness, explainability).\nGaps are specific and researchable (transportability, causal impact of deployment, fairness/harm metrics, operational interpretability, governance, ML security, long-term monitoring).\n\n\n\n6.3.2 Copilot\n\nTrends are relevant (deep learning shift, AutoML, edge AI).\nGaps cover core applied problems (XAI, data bias/quality, scalability).\nLess granular than ChatGPT, but still meaningful.\n\n\n\n6.3.3 Grok 3\n\nTrends/gaps include plausible topics (federated learning, OOD generalization, drift, fairness).\nHowever, it attaches precise percentages and effect sizes (e.g., “fairness audits 14%”, “OOD degrade ≥15%”) without sources—these should be rewritten as qualitative statements unless verified.\n\nTrends & gaps takeaway: ChatGPT is the most detailed and research-oriented; Copilot is solid but general; Grok is potentially insightful but numerically unreliable."
  },
  {
    "objectID": "km_sp2026/assignment.html#hypothesis-testable-and-relevant-1",
    "href": "km_sp2026/assignment.html#hypothesis-testable-and-relevant-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "6.4 2.4 Hypothesis (Testable and Relevant?)",
    "text": "6.4 2.4 Hypothesis (Testable and Relevant?)\n\n6.4.1 ChatGPT\n\nHypothesis about explainability increasing trust/adoption.\nClearly operationalized IV/DV and test design (A/B or experiment). Highly testable.\n\n\n\n6.4.2 Copilot\n\nSimilar hypothesis (human-in-the-loop explainability increases trust/adoption).\nTestable with IV/DV specified; good alignment with its identified gap (XAI).\n\n\n\n6.4.3 Grok 3\n\nHypothesis about causal-discovery priors improving OOD F1 by ≥18%.\nTestable in principle, but the “≥18%” threshold is an unsupported numeric claim; better phrased as “improves OOD performance” unless benchmarked.\n\nHypothesis takeaway: ChatGPT and Copilot propose the most defensible hypotheses; Grok’s is creative but needs removal of unsupported numeric target."
  },
  {
    "objectID": "km_sp2026/assignment.html#references-accuracy-check-1",
    "href": "km_sp2026/assignment.html#references-accuracy-check-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "6.5 2.5 References (Accuracy Check)",
    "text": "6.5 2.5 References (Accuracy Check)\n\n6.5.1 ChatGPT references\n\nNo explicit reference list was provided. This avoids fabricated citations but reduces academic verifiability.\n\n\n\n6.5.2 Copilot references (checked)\n\nLeCun, Bengio, & Hinton (2015), “Deep learning,” Nature 521:436–444 — Accurate. :contentReferenceoaicite:1\n\nEsteva et al. (2017), “Dermatologist-level classification of skin cancer…,” Nature 542 — Accurate. :contentReferenceoaicite:2\n\nChandola, Banerjee, & Kumar (2009), “Anomaly detection: A survey,” ACM Computing Surveys 41(3) — Accurate. :contentReferenceoaicite:3\n\nCopilot reference takeaway: citations are verifiable and appropriate.\n\n\n6.5.3 Grok 3 references (checked / flagged)\n\nAggarwal (2015), Data Mining: The Textbook (Springer) — Accurate. :contentReferenceoaicite:4\n\nChlingaryan et al. crop yield prediction — the commonly cited Chlingaryan review is 2018 (precision agriculture review), not clearly matching Grok’s “2019 crop yield prediction” citation. This should be treated as uncertain / needs correction. :contentReferenceoaicite:5\n\nLessmann et al. “Benchmarking state-of-the-art classification algorithms for credit scoring” — there is a well-known 2015 European Journal of Operational Research paper with this title; Grok’s “JORS 2019” style detail is likely inconsistent. Treat as needs correction. :contentReferenceoaicite:6\n\nPurushotham et al. “Benchmarking deep learning models on MIMIC-IV,” Nature Medicine 2022 — Not supported by verification; Purushotham’s benchmarking work is known in 2018 (clinical prediction tasks, MIMIC datasets) rather than “Nature Medicine 2022 MIMIC-IV” as stated. Flag as likely inaccurate unless replaced with a verified source. :contentReferenceoaicite:7\n\nGrok reference takeaway: mixed—some accurate, several require correction; numerical claims throughout should not be presented as factual without traceable sources."
  },
  {
    "objectID": "km_sp2026/assignment.html#summary-table-strengths-and-weaknesses-1",
    "href": "km_sp2026/assignment.html#summary-table-strengths-and-weaknesses-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "6.6 Summary Table (Strengths and Weaknesses)",
    "text": "6.6 Summary Table (Strengths and Weaknesses)\n\n6.6.1 Model | Strengths | Weaknesses / Risks | Best Contribution |\n|—|—|—|—| | ChatGPT | Strong cross-domain synthesis; detailed trends/gaps; clear hypothesis design | Methodology is more generic; lacks explicit references | Integrative synthesis + researchable gaps | | Copilot | Concise, report-ready structure; verifiable references; clear methods | Less cross-domain meta-synthesis; “45 studies” claim lacks trace | Clean structure + credible citations | | Grok 3 | Broad coverage; creative hypothesis; rich tables | Many unverifiable numeric claims; several references inconsistent | Interesting directions, but needs strict verification |"
  },
  {
    "objectID": "km_sp2026/assignment.html#step-2-conclusion-what-to-fix-in-step-3-1",
    "href": "km_sp2026/assignment.html#step-2-conclusion-what-to-fix-in-step-3-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "6.7 Step 2 Conclusion (What to fix in Step 3)",
    "text": "6.7 Step 2 Conclusion (What to fix in Step 3)\nBased on this analysis, the refined prompts in Step 3 should: 1. Force reproducible methodology (databases + Boolean query + eligibility + coding scheme). 2. Prohibit fabricated PRISMA counts or performance statistics unless sourced. 3. Require verifiable citations or explicitly label uncertain ones as “candidate references.” 4. Push for cross-domain synthesis (not only descriptive domain summaries)."
  },
  {
    "objectID": "km_sp2026/assignment.html#chatgpt-output-1",
    "href": "km_sp2026/assignment.html#chatgpt-output-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "7.1 ChatGPT output",
    "text": "7.1 ChatGPT output\n\n7.1.1 Abstract\nThis systematic literature review (SLR) synthesizes research on how data mining (DM) and machine learning (ML) are applied in three high-impact real-world domains—healthcare, finance, and education. The review summarizes common problem formulations (classification, risk prediction, anomaly detection, natural language processing, recommendation), dominant model families (linear/regularized models, tree-based ensembles, deep learning, and graph-based methods), typical data modalities (tabular, text, image, time series, graph), and evaluation practices. Across domains, the literature indicates recurring socio-technical constraints: distribution shift, data quality and missingness, fairness and accountability, privacy regulation, interpretability demands, and deployment frictions. Emerging trends include foundation models, multimodal learning, privacy-preserving computation, and MLOps standardization, while persistent gaps involve transportability/external validation, causal impact of deployment, domain-aligned interpretability, and secure/robust learning under adversarial settings. A bold, testable hypothesis is proposed linking explanation + uncertainty communication to adoption and performance outcomes in high-stakes decision workflows.\n\n\n\n7.1.2 1. Introduction\nThe proliferation of large-scale digital data has accelerated the adoption of DM and ML across sectors where decision-making is high-stakes and resource-constrained. DM traditionally emphasizes pattern discovery (e.g., clustering, association mining, anomaly detection) and descriptive insights, while ML emphasizes predictive and decision-oriented modeling under uncertainty. In practice, modern applied systems integrate both: feature engineering, supervised prediction, anomaly detection, text mining, and continuous monitoring.\nHealthcare, finance, and education share a common challenge: modeling decisions are embedded in institutional workflows, regulated environments, and heterogeneous populations. As a result, real-world performance depends not only on model accuracy but also on robustness to shift, interpretability for stakeholders, privacy constraints, and governance. This review aims to (i) summarize applications and methods, (ii) provide cross-domain synthesis and “fresh insights” about deployment tradeoffs, (iii) identify trends and gaps, and (iv) propose a testable hypothesis to advance future research.\n\n\n\n7.1.3 2. Methodology (Systematic Review Protocol)\n\n7.1.3.1 2.1 Research Questions\nRQ1: What are the predominant application tasks of DM/ML in healthcare, finance, and education, and what model families are most commonly used?\nRQ2: What constraints (data, evaluation, deployment, governance) shape model performance and real-world adoption across these domains?\n\n\n7.1.3.2 2.2 Search Strategy\nA structured search would typically be conducted in major digital libraries and indexing services such as: - IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (healthcare), and ERIC (education) (supplementary)."
  },
  {
    "objectID": "km_sp2026/assignment.html#copilot-output-1",
    "href": "km_sp2026/assignment.html#copilot-output-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "7.2 Copilot output",
    "text": "7.2 Copilot output\n\n7.2.1 Abstract\nThis systematic literature review synthesizes the state-of-the-art applications of Data Mining (DM) and Machine Learning (ML) across three critical domains: Healthcare, Finance, and Education. By analyzing 60 peer-reviewed studies published between 2015 and 2025, this review identifies a convergence of techniques—specifically Deep Learning and Natural Language Processing—while highlighting domain-specific challenges such as interpretability in healthcare, volatility modeling in finance, and privacy in educational data mining. The review reveals a critical gap in cross-domain transfer learning and proposes a bold, testable hypothesis regarding the efficacy of “Federated Transfer Learning” in data-scarce environments.\n\n\n7.2.2 1. Introduction\nThe ubiquity of big data has catalyzed a paradigm shift in decision-making processes. Machine Learning (ML) and Data Mining (DM) have evolved from experimental tools to foundational infrastructure. In healthcare, they drive precision medicine; in finance, they underpin algorithmic trading and fraud detection; and in education, they power adaptive learning platforms. This review aims to dissect the methodological commonalities and divergences across these sectors to inform future interdisciplinary research.\n\n\n7.2.3 2. Methodology\nThis review adheres to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to ensure rigor and replicability.\n\n7.2.3.1 2.1 Search Strategy\nA systematic search was executed across IEEE Xplore, ACM Digital Library, PubMed, and ERIC (Education Resources Information Center).\nSearch String: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\" OR \"Neural Networks\") AND (\"Application\" OR \"Case Study\") AND (\"Healthcare\" OR \"Finance\" OR \"Education\" OR \"Learning Analytics\")\n\n\n7.2.3.2 2.2 Inclusion and Exclusion Criteria\n\nInclusion: Peer-reviewed journal articles and high-impact conference proceedings (2015–2025); empirical studies with real-world datasets.\nExclusion: Pre-prints, non-English publications, and pure review papers (to avoid tertiary sourcing).\n\n\n\n7.2.3.3 2.3 Data Extraction & Analysis\nStudies were coded based on: (1) Domain, (2) Problem Type (Classification, Regression, Clustering), (3) Algorithm Family, (4) Dataset Size, and (5) Evaluation Metrics.\n\n\n\n7.2.4 3. Synthesis of Key Findings\n\n7.2.4.1 3.1 Healthcare: From Diagnostics to Prognostics\nThe healthcare sector exhibits the highest adoption of Deep Learning, particularly Convolutional Neural Networks (CNNs) for medical imaging. * Key Finding: ML models for diagnostic imaging (e.g., detecting diabetic retinopathy) have achieved sensitivity and specificity rates exceeding 95%, often outperforming human radiologists in controlled settings. * Methodology Trend: A shift from Support Vector Machines (SVM) to ensemble methods (Random Forest, XGBoost) for Electronic Health Record (EHR) analysis due to their handling of categorical variables and missing data.\n\n\n7.2.4.2 3.2 Finance: Risk, Fraud, and High-Frequency Trading\nFinancial applications prioritize speed and interpretability (for regulatory compliance). * Key Finding: Anomaly detection algorithms (Isolation Forests, Autoencoders) are the standard for credit card fraud detection, reducing false positives by up to 30% compared to rule-based systems. * Methodology Trend: Long Short-Term Memory (LSTM) networks dominate time-series forecasting for stock prices, though Transformer models (e.g., BERT for financial sentiment analysis) are emerging as powerful tools for processing unstructured market news.\n\n\n7.2.4.3 3.3 Education: The Rise of Learning Analytics\nEducational Data Mining (EDM) focuses on predicting student performance and retention. * Key Finding: Predictive models using student interaction logs (LMS data) can identify “at-risk” students as early as the third week of a semester with 85% accuracy. * Methodology Trend: Knowledge Tracing (KT) has evolved from Bayesian Knowledge Tracing (BKT) to Deep Knowledge Tracing (DKT), capturing complex temporal dependencies in student learning curves.\n\n\n\n7.2.5 4. Trends and Gaps\n\n7.2.5.1 4.1 Cross-Cutting Trends\n\nExplainable AI (XAI): Across all three domains, the “black box” nature of Deep Learning is a primary barrier to adoption. Techniques like SHAP (SHapley Additive exPlanations) and LIME are increasingly standard in published research.\nAutoML and Democratization: Tools that automate hyperparameter tuning and model selection are enabling domain experts (doctors, educators) to build models without deep technical expertise.\n\n\n\n7.2.5.2 4.2 Critical Gaps\n\nData Privacy and Ethics: While Differential Privacy is discussed theoretically, practical implementations in shared datasets (especially in Education and Healthcare) remain scarce.\nSiloed Innovation: Techniques successful in one domain (e.g., sequence modeling in NLP) are slow to permeate others (e.g., patient trajectory modeling), indicating a lack of cross-pollination.\nLack of Longitudinal Studies: Most studies report static performance metrics; few evaluate the long-term impact of algorithmic interventions on human outcomes.\n\n\n\n\n7.2.6 5. Proposed Hypothesis\nBased on the synthesis of findings, specifically the struggle with data scarcity in specialized sub-domains (e.g., rare diseases, specific learning disabilities), we propose the following Federated Transfer Learning Hypothesis:\n\nHypothesis: A Federated Transfer Learning (FTL) framework, pre-trained on a generic, large-scale dataset (e.g., general EHRs) and fine-tuned on decentralized, privacy-preserved institutional data (e.g., specific rare disease registries), will achieve a statistically significant improvement (p &lt; 0.05) in F1-score compared to locally trained models, without compromising data privacy standards (measured by epsilon-differential privacy).\n\nExperimental Design for Validation: 1. Control Group: Independent LSTM models trained on isolated hospital datasets for sepsis prediction. 2. Experimental Group: A global LSTM model pre-trained on public MIMIC-III data, then fine-tuned via Federated Averaging across the isolated hospitals. 3. Metrics: Compare AUC-ROC, F1-score, and communication overhead.\n\n\n7.2.7 6. Conclusion\nThe convergence of DM and ML in Healthcare, Finance, and Education is driving unprecedented efficiency and personalization. However, the maturation of these fields depends not on finding more complex algorithms, but on solving the “last mile” problems: interpretability, ethical data governance, and rigorous validation in dynamic, real-world environments. Future research must pivot from maximizing accuracy on static benchmarks to optimizing human-AI collaboration.\n\n\n7.2.8 References\n(Placeholder for BibTeX references)\n\nRajkomar, A., et al. (2018). Scalable and accurate deep learning with electronic health records. NPJ Digital Medicine.\nDixon, M. F., Halperin, I., & Bilokon, P. (2020). Machine Learning in Finance: From Theory to Practice. Springer.\nBaker, R. S., & Inventado, P. S. (2014). Educational data mining and learning analytics. Learning Analytics."
  },
  {
    "objectID": "km_sp2026/assignment.html#grok-3-output-1",
    "href": "km_sp2026/assignment.html#grok-3-output-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "7.3 Grok 3 output",
    "text": "7.3 Grok 3 output\n\n7.3.1 Executive Summary\nThis systematic review analyzes 108 empirical studies (2018-2024) across healthcare (42%), finance (35%), and education (23%). Using PRISMA 2020 methodology: Performance: AUC 0.92, F1 0.89\nTechniques: Deep learning 61%, Ensembles 28%\nTrends: XAI +350%, Federated +420%\nGaps: Fairness 11%, Causal &lt;4% Hypothesis: Multi-task causal DM-ML frameworks outperform single-task models by ≥22% in cross-domain transfer for minority subpopulations.\n(128 words) ### 1. Introduction Healthcare produces 2.5 quintillion bytes daily from EHRs, imaging, wearables. Finance processes $6.6T transactions daily. Education platforms serve 1.7B learners. Data mining (clustering, rules, anomalies) and machine learning (supervised/unsupervised/reinforcement) unlock insights. Research Questions: 1. Dominant DM/ML methods per domain? 2. Cross-domain performance patterns? 3. Trends and critical gaps? 4. Testable hypothesis from synthesis?\n\n\n7.3.2 2. Methodology\n\n7.3.2.1 2.1 PRISMA Protocol\nSearch: October 15, 2024 across Scopus (847), PubMed (392), Web of Science (285), IEEE (176), ERIC (89). Query: (“data mining” OR “machine learning”) AND (healthcare OR finance OR education) AND (“real world” OR “case study”) AND (2018:2024)\nFlow: 1,836 → screened 1,424 → full-text 289 → included 108 (deduped 412) #### 2.2 Quality Assessment | Domain | Selection Bias | Performance Bias | Applicability | |——–|—————-|——————|—————| | Healthcare | Low | Low | Moderate | | Finance | Low | Moderate | Low | | Education | Moderate | High | High |\n\n\n\n7.3.3 3. Domain Findings\n\n7.3.3.1 3.1 Healthcare (n=45)\n\n\n\nApplication\nAlgorithm\nDataset\nPerformance\n\n\n\n\nDisease Prediction\nCNN-LSTM\nMIMIC-IV\nAUC 0.94\n\n\nReadmission\nXGBoost\nUCI Heart\nF1 0.91\n\n\nDrug Discovery\nGraph NNs\nPubChem\nP@10 0.88\n\n\nSepsis\nGRU\neICU\n7h lead time\n\n\n\nInsight: Multimodal fusion +17% AUC vs unimodal.\n\n\n7.3.3.2 3.2 Finance (n=38)\n\nFraud: Isolation Forest, Recall 99.7% (2.4B transactions)\nCredit: LightGBM, KS 0.65 (15M loans)\nTrading: Transformer+RL, Sharpe 2.1\n\n\n\n7.3.3.3 3.3 Education (n=25)\n\nDropout prediction: LSTM AUC 0.89 (1M learners)\nPersonalized paths: Bandits +15% completion\nPlagiarism: BERT F1 0.93\n\n\n\n\n7.3.4 4. Cross-Model Collaboration (Synthesis)\n\n7.3.4.1 4.1 What I retained from each model (best elements)\nTo produce a final, academically sound review, I integrated the strongest elements from each model while filtering out unverifiable claims.\n\nFrom ChatGPT (strength: cross-domain synthesis and researchable gaps)\n\nKept the cross-domain synthesis logic (shared deployment constraints across domains).\nKept the richer and more current set of trends and gaps (e.g., MLOps, robustness, privacy-preserving ML, causal ML).\n\nFrom Copilot (strength: replicable methodology template and concise structure)\n\nKept the clearer “protocol-like” structure for Methods (databases, search string, eligibility criteria, and coding fields).\nAdopted its concise domain write-up style (bullets for tasks, model families, data modalities, metrics).\n\nFrom Grok 3 (strength: creative, forward-looking hypothesis framing)\n\nKept the idea of a “bolder” hypothesis that pushes beyond descriptive synthesis.\nDid not retain Grok 3’s numeric PRISMA counts, percentages, performance medians, or global economic-value claims because they were not verifiable from the prompt context.\n\n\n\n\n7.3.4.2 4.2 What I removed or constrained (quality control rules)\nAcross Copilot and Grok 3, the outputs included precise quantitative claims (e.g., number of studies screened, included studies, AUC/accuracy medians, percentage growth). Because I did not conduct an actual database search and did not document a PRISMA flow, these claims were treated as unsubstantiated and excluded from the synthesis.\nTo ensure academic integrity, the final synthesis must: 1. Avoid fabricated PRISMA counts and performance numbers unless explicitly supported by traceable sources. 2. Use verifiable references; if uncertain, label as “candidate reference.” 3. Emphasize cross-domain mechanisms (why deployment succeeds/fails), not just domain-by-domain listing.\n\n\n7.3.4.3 4.3 Synthesis Prompt for My Preferred Model (ChatGPT)\n\n\n\n7.3.5 Applications of Data Mining and Machine Learning in Real-World Domains: A Structured Systematic Literature Review\n\n7.3.5.1 Abstract\nThis structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n7.3.5.2 1. Introduction\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n7.3.5.3 2. Methodology (Structured SLR Approach)\n\n7.3.5.3.1 2.1 Search Strategy\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n7.3.5.3.2 2.2 Inclusion and Exclusion Criteria\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n7.3.5.3.3 2.3 Screening and Study Selection\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n7.3.5.3.4 2.4 Synthesis Approach\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n7.3.5.4 3. Findings by Domain (Applications and Key Patterns)\n\n7.3.5.4.1 3.1 Healthcare\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n7.3.5.4.2 3.2 Finance (Fraud, Risk, Trading, Credit)\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n7.3.5.4.3 3.3 Public Policy and Government Analytics\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n7.3.5.4.4 3.4 Cybersecurity\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n7.3.5.4.5 3.5 Education (Learning Analytics)\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n7.3.5.5 4. Cross-Domain Synthesis: What Works and Why\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n7.3.5.6 5. Emerging Trends (≥5)\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n7.3.5.7 6. Research Gaps (≥5)\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n7.3.5.8 7. Proposed Testable Hypothesis\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n7.3.5.8.1 Operationalization\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n7.3.5.9 8. Conclusion\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability."
  },
  {
    "objectID": "km_sp2026/assignment.html#how-did-each-model-approach-the-systematic-review-differently-1",
    "href": "km_sp2026/assignment.html#how-did-each-model-approach-the-systematic-review-differently-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "8.1 How did each model approach the systematic review differently?",
    "text": "8.1 How did each model approach the systematic review differently?\n\n8.1.1 ChatGPT\nChatGPT approached the task as a cross-domain conceptual synthesis. It emphasized (1) a clean SLR-like structure, (2) consistent domain-by-domain summaries (tasks, model families, data, evaluation, limitations), and (3) a strong cross-domain “what works and why” section. Its methodology description was credible but intentionally conservative—describing how an SLR should be done rather than asserting specific PRISMA counts or performance statistics.\n\n\n8.1.2 Copilot\nCopilot focused on producing a report-ready template with clear headings and a direct PRISMA framing. It typically excelled at concise structuring (methods → findings → trends/gaps → hypothesis) and gave concrete components such as a search string and coding fields. However, it tended to state specific scope claims (e.g., “X studies analyzed,” “2015–2025”) without showing a traceable screening log, so those details need user verification before being treated as factual.\n\n\n8.1.3 Grok 3\nGrok 3 prioritized a high-confidence, metrics-driven narrative. It presented a very “scientific-looking” review with detailed counts, percentages, pooled metrics, and strongly quantified trends and effects. While this style can look impressive, it introduced the highest risk of unverifiable or fabricated quantitative claims when the prompt did not provide underlying data. In my workflow, Grok 3 was most useful for generating bold hypotheses and highlighting possible frontier directions—but its numbers required strict filtering."
  },
  {
    "objectID": "km_sp2026/assignment.html#which-prompt-refinements-yielded-the-best-results-for-each-model-1",
    "href": "km_sp2026/assignment.html#which-prompt-refinements-yielded-the-best-results-for-each-model-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "8.2 Which prompt refinements yielded the best results for each model?",
    "text": "8.2 Which prompt refinements yielded the best results for each model?\n\n8.2.1 For ChatGPT\nFor ChatGPT, the most effective refinements were: - Forcing a reproducible Methods protocol (databases, one Boolean query, explicit inclusion/exclusion criteria, coding framework). - Requiring ≥5 trends and ≥5 gaps as researchable statements, which improved specificity. - Adding an integrity rule (“no fabricated PRISMA counts or performance numbers”) strengthened academic defensibility.\n\n\n8.2.2 For Copilot\nFor Copilot, the most effective refinements were: - Enforcing fixed headings and a “must-follow” outline (RQs → Methods → Findings → Trends/Gaps → Hypothesis → References). - Explicitly instructing: “If counts are unknown, say ‘not available’”, which reduces unsupported claims. - Requiring a coding framework (domain/task/modality/model/metric/deployment/risks) improved systematic clarity.\n\n\n8.2.3 For Grok 3\nFor Grok 3, the most effective refinements were: - Adding strict constraints: no numeric screening counts, no pooled performance metrics, no growth percentages unless cited. - Requiring that uncertain citations be labeled “candidate references” rather than asserted as true. - Asking for “fresh insights” as tradeoffs/tensions (accuracy vs interpretability, privacy vs utility, robustness vs performance) instead of numeric-heavy summaries."
  },
  {
    "objectID": "km_sp2026/assignment.html#what-did-you-learn-about-leveraging-ai-for-structured-academic-reviews-1",
    "href": "km_sp2026/assignment.html#what-did-you-learn-about-leveraging-ai-for-structured-academic-reviews-1",
    "title": "Assignment 2: Prompt Exercise",
    "section": "8.3 What did you learn about leveraging AI for structured academic reviews?",
    "text": "8.3 What did you learn about leveraging AI for structured academic reviews?\n\nAI is strongest at structure and synthesis, not at unverifiable specifics.\nThe models can reliably produce coherent organization (SLR headings), domain taxonomies, and cross-domain themes. But unless the user provides the evidence base (search results, screened papers), AI may generate overly specific numbers (PRISMA counts, pooled AUC) that should not be treated as factual.\nPrompting must operationalize rigor.\nThe best results came from prompts that required: explicit databases, a reproducible Boolean query, eligibility criteria, a screening workflow description, and a coding framework. These constraints transform “general summaries” into a workflow-aligned SLR draft.\nIntegrity constraints are essential for academic use.\nAdding rules like “do not fabricate counts or performance metrics” and “label uncertain citations as candidate references” greatly improved reliability. This also clarified which parts of the output are safe to publish in a course website.\nCross-model collaboration works best when each model is assigned a role.\nIn synthesis, I treated ChatGPT as the main integrator for cross-domain reasoning, Copilot as a structure/methods template engine, and Grok 3 as an idea generator for bold hypotheses and emerging directions—while filtering out unsupported quantitative claims.\n\nOverall, the process showed that AI can accelerate academic drafting and conceptual synthesis, but the user must impose methodological discipline and verification rules to produce an academically credible systematic review."
  },
  {
    "objectID": "km_sp2026/assignment2.html",
    "href": "km_sp2026/assignment2.html",
    "title": "Assignment 2: Prompt Exercise",
    "section": "",
    "text": "This structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n\n\n\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n\n\n\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability.\n\n\n\n\n\n\nThis systematic literature review examines the application of Data Mining (DM) and Machine Learning (ML) across various real-world domains over the past decade. By synthesizing findings from 45 selected studies, this review identifies key trends in healthcare, finance, and cybersecurity. The analysis reveals a significant shift towards Deep Learning (DL) techniques, although explainability remains a critical gap. A testable hypothesis regarding the trade-off between model complexity and interpretability in high-stakes domains is proposed.\n\n\n\nThe exponential growth of data has catalyzed the adoption of Data Mining (DM) and Machine Learning (ML) technologies across diverse sectors. From predictive analytics in healthcare to fraud detection in finance, these technologies are reshaping decision-making processes. This review aims to systematically analyze the state-of-the-art applications, focusing on methodology, impact, and prevailing challenges.\n\n\n\nThis review follows the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines.\n\n\nA comprehensive search was conducted on IEEE Xplore, ACM Digital Library, and PubMed using the search string: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\") AND (\"Application\" OR \"Real-world\") AND (\"Healthcare\" OR \"Finance\" OR \"Cybersecurity\").\n\n\n\nInclusion Criteria: - Peer-reviewed articles published between 2014 and 2024. - Studies focusing on practical, real-world implementations. - Articles written in English.\nExclusion Criteria: - Purely theoretical papers without empirical validation. - Survey papers (to avoid redundancy). - Non-peer-reviewed white papers.\n\n\n\nData was extracted based on: 1. Domain of Application 2. Algorithms Used 3. Dataset Scale and Type 4. Performance Metrics 5. Reported Challenges\n\n\n\n\n\n\nHealthcare remains the most prolific domain for ML applications. * Diagnostics: Convolutional Neural Networks (CNNs) have achieved parity with human experts in analyzing medical imaging (X-rays, MRIs). * Prognostics: DM techniques are widely used for predicting patient readmission rates and disease progression. * Key Insight: While accuracy is high, clinical adoption is hindered by the “black box” nature of advanced models.\n\n\n\nThe financial sector heavily utilizes DM for risk management and fraud detection. * Fraud Detection: Ensemble methods like Random Forest and Gradient Boosting Machines (GBM) are preferred for their robustness against imbalanced datasets. * Algorithmic Trading: Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are standard for time-series forecasting.\n\n\n\nWith the rise of cyber threats, ML has become integral to intrusion detection systems (IDS). * Anomaly Detection: Unsupervised learning techniques (e.g., K-Means, Autoencoders) are effective in identifying zero-day attacks. * Trend: There is a growing shift towards adversarial machine learning to robustness testing.\n\n\n\n\n\n\n\nShift to Deep Learning: A clear migration from traditional statistical methods (Regression, SVM) to Deep Learning architectures (CNN, Transformer models) across all domains.\nAutoML: Increasing use of Automated Machine Learning tools to democratize AI application for non-experts.\nEdge AI: Deployment of lightweight models on IoT devices, particularly in healthcare monitoring and industrial maintenance.\n\n\n\n\n\nExplainability (XAI): A significant gap exists between model performance and interpretability. In high-stakes domains like law and medicine, this lack of transparency is a barrier to trust and regulatory compliance.\nData Quality and Bias: Many real-world datasets suffer from bias, leading to unfair algorithmic outcomes. Standardization in data preprocessing is lacking.\nScalability: While models perform well in controlled environments, scalability issues often arise during full-scale deployment.\n\n\n\n\n\nBased on the identified gap in Explainable AI (XAI), we propose the following hypothesis:\nHypothesis: In high-stakes decision-making environments (e.g., medical diagnosis, loan approval), the integration of “human-in-the-loop” interactive explainability features will statistically significantly increase user trust and adoption rates compared to black-box models with higher raw accuracy.\nProposed Experiment: * Variables: Independent variable: Type of model interface (Black-box vs. XAI dashboard). Dependent variable: User trust score (Likert scale) and adoption rate. * Method: A/B testing with domain experts using a controlled dataset.\n\n\n\nThis review highlights the transformative power of DM and ML. While technical capabilities have advanced rapidly, the socio-technical challenges of trust, explainability, and bias remain the new frontier for research. Future work must bridge the gap between high-performance algorithms and human-interpretable insights.\n\n\n\n\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.\nEsteva, A., et al. (2017). Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639), 115-118.\nChandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58.\n\n\n\n\n\n\n\nThis systematic literature review examines applications of data mining (DM) and machine learning (ML) across real-world domains from 92 peer-reviewed studies (2019–2024). Following PRISMA guidelines, 1,856 records were screened, yielding high-quality empirical evidence. Key findings reveal deep learning (58%) and ensemble methods (32%) dominating healthcare, finance, transportation, agriculture, manufacturing, and retail, achieving median AUC=0.91 and accuracy=93%. Trends: explainable AI (+42%), federated learning (+380%), edge ML.\nGaps: fairness audits (14%), OOD generalization, model drift.\nHypothesis: Hybrid DM-ML with causal discovery improves OOD F1-scores by ≥18%. (Word count: 112)\n\n\n\nData mining extracts patterns from large datasets using clustering, association rules, and anomaly detection. Machine learning enables predictive modeling via supervised, unsupervised, and reinforcement learning paradigms. Real-world applications span healthcare diagnostics to financial fraud detection, generating economic value exceeding $13 trillion by 2030. Objectives: - Synthesize empirical applications across domains - Identify trends and methodological gaps\n- Propose testable research hypothesis\n\n\n\n\n\nDatabases (April 2024): Scopus, Web of Science, PubMed, IEEE Xplore, ACM DL.\nSearch string: (\"data mining\" OR \"machine learning\") AND (healthcare OR finance OR agriculture) AND (\"real world\" OR \"case study\") AND (2019:2024) Records: 1,856 → screened 1,428 → full-text 312 → included 92 (κ=0.89) ##### 2.2 Inclusion Criteria - Empirical studies with real-world datasets (≥50k instances)\n- Quantitative performance metrics (AUC, F1, accuracy) - Peer-reviewed journals/conferences (2019–2024) ##### 2.3 Quality Assessment Newcastle-Ottawa Scale (modified): High (55%), Moderate (37%), Low (8%)\n\n\n\n\n\n\n\n\n\nDomain\nStudies\nKey Algorithms\nMedian AUC\nExample\n\n\n\n\nHealthcare\n27\nCNN, LSTM\n0.94\nPneumonia detection (94%)\n\n\nFinance\n20\nXGBoost, GNN\n0.93\nFraud detection (99.8%)\n\n\nTransport\n15\nGCN, RL\n0.88\nTraffic forecasting\n\n\nAgriculture\n12\nU-Net, ViT\n0.91\nCrop yield prediction\n\n\nManufacturing\n11\nLSTM\n0.92\nPredictive maintenance\n\n\nRetail\n7\nGraphSAGE\n0.89\nRecommendations\n\n\n\n\n\n\nAggregated metrics (n=92): - Median accuracy: 93.2% (IQR: 89-96%) - Median AUC-ROC: 0.91 (IQR: 0.87-0.94)\n- Median F1-score: 0.89 (IQR: 0.84-0.93)\n\n\n\n\n\n\nAlgorithm Evolution (2019-2024): • Deep Learning: 41% → 72% (+76%) • Explainable AI: +42% post-2021 • Federated Learning: +380% • Edge/TinyML: 27% of IoT studies\n\n\n\n\nAlgorithmic Fairness: 86% unassessed (ΔAUC=0.12 demographic gaps)\nOOD Generalization: 73% degrade ≥15% on new domains\nModel Drift: 91% lack monitoring (-22% accuracy/12mo)\nCausal Inference: &lt;5% use causal models\nLow-Resource: &lt;3% LMIC applications\n\n\n\n\n\nH₁: Hybrid DM-ML frameworks integrating causal discovery (NOTEARS algorithm) as priors for neural networks will achieve ≥18% higher F1-scores under out-of-distribution shifts vs. standard supervised learning. Test Protocol: Datasets: MIMIC-IV (health), NYC Taxi (transport), Rossmann Sales (retail) Metrics: F1_macro, AUCPR, calibration error Validation: 10-fold CV + temporal holdout Power: α=0.05, power=0.90 (n=10k/fold) Rationale: Causal graphs constrain spurious correlations, enhancing robustness to covariate/concept shift.\n\n\n\nDM/ML delivers production-grade performance across domains: Strengths: - Surpasses human experts (radiology: ML 0.94 vs human 0.88) - Scalable to petabyte-scale data - Real-time deployment proven Challenges: - Reproducibility crisis (23% open code) - Ethical deployment gaps - Production drift unaddressed Recommendations: 1. Mandate fairness audits 2. Standardize causal benchmarks\n3. Fund hybrid DM-ML research\n\n\n\nThis review of 92 studies confirms DM/ML transformation across six domains while exposing critical gaps in robustness and ethics. Causal-hybrid approaches offer the path forward. Total word count: 2,018\n\n\n\nAggarwal, C.C. Data Mining: The Textbook. Springer, 2015.\nChlingaryan, A. et al. “Crop yield prediction using machine learning.” Computers and Electronics in Agriculture, 2019.\nGulshan, V. et al. “Development and validation of a deep learning algorithm for detection of diabetic retinopathy.” JAMA, 2016.\nLessmann, S. et al. “Benchmarking state-of-the-art classification algorithms for credit scoring.” JORS, 2019.\nPurushotham, S. et al. “Benchmarking deep learning models on MIMIC-IV.” Nature Medicine, 2022.\nZheng, X. et al. “DAGs with NO TEARS.” NeurIPS, 2018. (Full 92-study bibliography available in supplementary materials)"
  },
  {
    "objectID": "km_sp2026/assignment2.html#model-runs-raw-outputs",
    "href": "km_sp2026/assignment2.html#model-runs-raw-outputs",
    "title": "Assignment 2: Prompt Exercise",
    "section": "",
    "text": "This structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n\n\n\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n\n\n\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability.\n\n\n\n\n\n\nThis systematic literature review examines the application of Data Mining (DM) and Machine Learning (ML) across various real-world domains over the past decade. By synthesizing findings from 45 selected studies, this review identifies key trends in healthcare, finance, and cybersecurity. The analysis reveals a significant shift towards Deep Learning (DL) techniques, although explainability remains a critical gap. A testable hypothesis regarding the trade-off between model complexity and interpretability in high-stakes domains is proposed.\n\n\n\nThe exponential growth of data has catalyzed the adoption of Data Mining (DM) and Machine Learning (ML) technologies across diverse sectors. From predictive analytics in healthcare to fraud detection in finance, these technologies are reshaping decision-making processes. This review aims to systematically analyze the state-of-the-art applications, focusing on methodology, impact, and prevailing challenges.\n\n\n\nThis review follows the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines.\n\n\nA comprehensive search was conducted on IEEE Xplore, ACM Digital Library, and PubMed using the search string: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\") AND (\"Application\" OR \"Real-world\") AND (\"Healthcare\" OR \"Finance\" OR \"Cybersecurity\").\n\n\n\nInclusion Criteria: - Peer-reviewed articles published between 2014 and 2024. - Studies focusing on practical, real-world implementations. - Articles written in English.\nExclusion Criteria: - Purely theoretical papers without empirical validation. - Survey papers (to avoid redundancy). - Non-peer-reviewed white papers.\n\n\n\nData was extracted based on: 1. Domain of Application 2. Algorithms Used 3. Dataset Scale and Type 4. Performance Metrics 5. Reported Challenges\n\n\n\n\n\n\nHealthcare remains the most prolific domain for ML applications. * Diagnostics: Convolutional Neural Networks (CNNs) have achieved parity with human experts in analyzing medical imaging (X-rays, MRIs). * Prognostics: DM techniques are widely used for predicting patient readmission rates and disease progression. * Key Insight: While accuracy is high, clinical adoption is hindered by the “black box” nature of advanced models.\n\n\n\nThe financial sector heavily utilizes DM for risk management and fraud detection. * Fraud Detection: Ensemble methods like Random Forest and Gradient Boosting Machines (GBM) are preferred for their robustness against imbalanced datasets. * Algorithmic Trading: Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are standard for time-series forecasting.\n\n\n\nWith the rise of cyber threats, ML has become integral to intrusion detection systems (IDS). * Anomaly Detection: Unsupervised learning techniques (e.g., K-Means, Autoencoders) are effective in identifying zero-day attacks. * Trend: There is a growing shift towards adversarial machine learning to robustness testing.\n\n\n\n\n\n\n\nShift to Deep Learning: A clear migration from traditional statistical methods (Regression, SVM) to Deep Learning architectures (CNN, Transformer models) across all domains.\nAutoML: Increasing use of Automated Machine Learning tools to democratize AI application for non-experts.\nEdge AI: Deployment of lightweight models on IoT devices, particularly in healthcare monitoring and industrial maintenance.\n\n\n\n\n\nExplainability (XAI): A significant gap exists between model performance and interpretability. In high-stakes domains like law and medicine, this lack of transparency is a barrier to trust and regulatory compliance.\nData Quality and Bias: Many real-world datasets suffer from bias, leading to unfair algorithmic outcomes. Standardization in data preprocessing is lacking.\nScalability: While models perform well in controlled environments, scalability issues often arise during full-scale deployment.\n\n\n\n\n\nBased on the identified gap in Explainable AI (XAI), we propose the following hypothesis:\nHypothesis: In high-stakes decision-making environments (e.g., medical diagnosis, loan approval), the integration of “human-in-the-loop” interactive explainability features will statistically significantly increase user trust and adoption rates compared to black-box models with higher raw accuracy.\nProposed Experiment: * Variables: Independent variable: Type of model interface (Black-box vs. XAI dashboard). Dependent variable: User trust score (Likert scale) and adoption rate. * Method: A/B testing with domain experts using a controlled dataset.\n\n\n\nThis review highlights the transformative power of DM and ML. While technical capabilities have advanced rapidly, the socio-technical challenges of trust, explainability, and bias remain the new frontier for research. Future work must bridge the gap between high-performance algorithms and human-interpretable insights.\n\n\n\n\nLeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436-444.\nEsteva, A., et al. (2017). Dermatologist-level classification of skin cancer with deep neural networks. Nature, 542(7639), 115-118.\nChandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58.\n\n\n\n\n\n\n\nThis systematic literature review examines applications of data mining (DM) and machine learning (ML) across real-world domains from 92 peer-reviewed studies (2019–2024). Following PRISMA guidelines, 1,856 records were screened, yielding high-quality empirical evidence. Key findings reveal deep learning (58%) and ensemble methods (32%) dominating healthcare, finance, transportation, agriculture, manufacturing, and retail, achieving median AUC=0.91 and accuracy=93%. Trends: explainable AI (+42%), federated learning (+380%), edge ML.\nGaps: fairness audits (14%), OOD generalization, model drift.\nHypothesis: Hybrid DM-ML with causal discovery improves OOD F1-scores by ≥18%. (Word count: 112)\n\n\n\nData mining extracts patterns from large datasets using clustering, association rules, and anomaly detection. Machine learning enables predictive modeling via supervised, unsupervised, and reinforcement learning paradigms. Real-world applications span healthcare diagnostics to financial fraud detection, generating economic value exceeding $13 trillion by 2030. Objectives: - Synthesize empirical applications across domains - Identify trends and methodological gaps\n- Propose testable research hypothesis\n\n\n\n\n\nDatabases (April 2024): Scopus, Web of Science, PubMed, IEEE Xplore, ACM DL.\nSearch string: (\"data mining\" OR \"machine learning\") AND (healthcare OR finance OR agriculture) AND (\"real world\" OR \"case study\") AND (2019:2024) Records: 1,856 → screened 1,428 → full-text 312 → included 92 (κ=0.89) ##### 2.2 Inclusion Criteria - Empirical studies with real-world datasets (≥50k instances)\n- Quantitative performance metrics (AUC, F1, accuracy) - Peer-reviewed journals/conferences (2019–2024) ##### 2.3 Quality Assessment Newcastle-Ottawa Scale (modified): High (55%), Moderate (37%), Low (8%)\n\n\n\n\n\n\n\n\n\nDomain\nStudies\nKey Algorithms\nMedian AUC\nExample\n\n\n\n\nHealthcare\n27\nCNN, LSTM\n0.94\nPneumonia detection (94%)\n\n\nFinance\n20\nXGBoost, GNN\n0.93\nFraud detection (99.8%)\n\n\nTransport\n15\nGCN, RL\n0.88\nTraffic forecasting\n\n\nAgriculture\n12\nU-Net, ViT\n0.91\nCrop yield prediction\n\n\nManufacturing\n11\nLSTM\n0.92\nPredictive maintenance\n\n\nRetail\n7\nGraphSAGE\n0.89\nRecommendations\n\n\n\n\n\n\nAggregated metrics (n=92): - Median accuracy: 93.2% (IQR: 89-96%) - Median AUC-ROC: 0.91 (IQR: 0.87-0.94)\n- Median F1-score: 0.89 (IQR: 0.84-0.93)\n\n\n\n\n\n\nAlgorithm Evolution (2019-2024): • Deep Learning: 41% → 72% (+76%) • Explainable AI: +42% post-2021 • Federated Learning: +380% • Edge/TinyML: 27% of IoT studies\n\n\n\n\nAlgorithmic Fairness: 86% unassessed (ΔAUC=0.12 demographic gaps)\nOOD Generalization: 73% degrade ≥15% on new domains\nModel Drift: 91% lack monitoring (-22% accuracy/12mo)\nCausal Inference: &lt;5% use causal models\nLow-Resource: &lt;3% LMIC applications\n\n\n\n\n\nH₁: Hybrid DM-ML frameworks integrating causal discovery (NOTEARS algorithm) as priors for neural networks will achieve ≥18% higher F1-scores under out-of-distribution shifts vs. standard supervised learning. Test Protocol: Datasets: MIMIC-IV (health), NYC Taxi (transport), Rossmann Sales (retail) Metrics: F1_macro, AUCPR, calibration error Validation: 10-fold CV + temporal holdout Power: α=0.05, power=0.90 (n=10k/fold) Rationale: Causal graphs constrain spurious correlations, enhancing robustness to covariate/concept shift.\n\n\n\nDM/ML delivers production-grade performance across domains: Strengths: - Surpasses human experts (radiology: ML 0.94 vs human 0.88) - Scalable to petabyte-scale data - Real-time deployment proven Challenges: - Reproducibility crisis (23% open code) - Ethical deployment gaps - Production drift unaddressed Recommendations: 1. Mandate fairness audits 2. Standardize causal benchmarks\n3. Fund hybrid DM-ML research\n\n\n\nThis review of 92 studies confirms DM/ML transformation across six domains while exposing critical gaps in robustness and ethics. Causal-hybrid approaches offer the path forward. Total word count: 2,018\n\n\n\nAggarwal, C.C. Data Mining: The Textbook. Springer, 2015.\nChlingaryan, A. et al. “Crop yield prediction using machine learning.” Computers and Electronics in Agriculture, 2019.\nGulshan, V. et al. “Development and validation of a deep learning algorithm for detection of diabetic retinopathy.” JAMA, 2016.\nLessmann, S. et al. “Benchmarking state-of-the-art classification algorithms for credit scoring.” JORS, 2019.\nPurushotham, S. et al. “Benchmarking deep learning models on MIMIC-IV.” Nature Medicine, 2022.\nZheng, X. et al. “DAGs with NO TEARS.” NeurIPS, 2018. (Full 92-study bibliography available in supplementary materials)"
  },
  {
    "objectID": "km_sp2026/assignment2.html#structure-systematic-review-format",
    "href": "km_sp2026/assignment2.html#structure-systematic-review-format",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.1 2.1 Structure (Systematic Review Format)",
    "text": "2.1 2.1 Structure (Systematic Review Format)\n\n2.1.1 ChatGPT\n\nClear SLR-like structure: Abstract → Introduction → Methodology → Domain findings → Trends → Gaps → Hypothesis → Conclusion.\nMethodology is conceptually complete (databases, inclusion/exclusion, PRISMA-style workflow, synthesis plan) but remains generic (no fixed time window; example search string only; no explicit screening counts).\n\n\n\n2.1.2 Copilot\n\nStrong SLR structure with PRISMA mention and clearly separated sections (methods/findings/trends/hypothesis/references).\nProvides an explicit search string and eligibility criteria; includes “data extraction” fields (good for systematic coding).\nMentions “45 selected studies” but does not show screening trace (counts or PRISMA flow). This is acceptable if framed as “example workflow,” but risky if presented as a factual result.\n\n\n\n2.1.3 Grok 3\n\nAppears highly “formal” (PRISMA, κ statistic, quality assessment scale, tables, performance synthesis).\nHowever, it contains many precise quantitative claims (records screened, included studies, κ, percentages, median AUC/accuracy) without verifiable evidence. For an assignment prompt output, these should be treated as unsubstantiated unless the model provides traceable sources.\n\nStructure takeaway: Copilot is the most “report-ready” and concise; ChatGPT is the most coherent and balanced; Grok 3 is highly structured but overconfident with unverifiable numbers."
  },
  {
    "objectID": "km_sp2026/assignment2.html#synthesis-coverage-and-analytical-depth",
    "href": "km_sp2026/assignment2.html#synthesis-coverage-and-analytical-depth",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.2 2.2 Synthesis (Coverage and Analytical Depth)",
    "text": "2.2 2.2 Synthesis (Coverage and Analytical Depth)\n\n2.2.1 ChatGPT\n\nBroad multi-domain synthesis (healthcare, finance, public policy, cybersecurity, education).\nStrong “cross-domain” logic: shared success conditions (decision context, data pipelines, evaluation beyond accuracy, human-in-the-loop, deployment monitoring).\n\n\n\n2.2.2 Copilot\n\nFocuses on three domains (healthcare/finance/cybersecurity), with clear bullet-point application summaries.\nSlightly less cross-domain meta-synthesis than ChatGPT, but the domain summaries are easy to read and academically styled.\n\n\n\n2.2.3 Grok 3\n\nCovers more domains and presents a comparative table.\nBut the synthesis depends heavily on quantitative performance summaries (median AUC, accuracy, domain-level metrics) that are not supported by sources; therefore, the analytic value is weakened by credibility concerns.\n\nSynthesis takeaway: ChatGPT provides the strongest cross-domain reasoning; Copilot provides concise, structured synthesis; Grok provides breadth but with credibility issues."
  },
  {
    "objectID": "km_sp2026/assignment2.html#trends-and-research-gaps",
    "href": "km_sp2026/assignment2.html#trends-and-research-gaps",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.3 2.3 Trends and Research Gaps",
    "text": "2.3 2.3 Trends and Research Gaps\n\n2.3.1 ChatGPT\n\nTrends are modern and detailed (foundation models, multimodal learning, privacy-preserving ML, causal ML, MLOps, robustness, explainability).\nGaps are specific and researchable (transportability, causal impact of deployment, fairness/harm metrics, operational interpretability, governance, ML security, long-term monitoring).\n\n\n\n2.3.2 Copilot\n\nTrends are relevant (deep learning shift, AutoML, edge AI).\nGaps cover core applied problems (XAI, data bias/quality, scalability).\nLess granular than ChatGPT, but still meaningful.\n\n\n\n2.3.3 Grok 3\n\nTrends/gaps include plausible topics (federated learning, OOD generalization, drift, fairness).\nHowever, it attaches precise percentages and effect sizes (e.g., “fairness audits 14%”, “OOD degrade ≥15%”) without sources—these should be rewritten as qualitative statements unless verified.\n\nTrends & gaps takeaway: ChatGPT is the most detailed and research-oriented; Copilot is solid but general; Grok is potentially insightful but numerically unreliable."
  },
  {
    "objectID": "km_sp2026/assignment2.html#hypothesis-testable-and-relevant",
    "href": "km_sp2026/assignment2.html#hypothesis-testable-and-relevant",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.4 2.4 Hypothesis (Testable and Relevant?)",
    "text": "2.4 2.4 Hypothesis (Testable and Relevant?)\n\n2.4.1 ChatGPT\n\nHypothesis about explainability increasing trust/adoption.\nClearly operationalized IV/DV and test design (A/B or experiment). Highly testable.\n\n\n\n2.4.2 Copilot\n\nSimilar hypothesis (human-in-the-loop explainability increases trust/adoption).\nTestable with IV/DV specified; good alignment with its identified gap (XAI).\n\n\n\n2.4.3 Grok 3\n\nHypothesis about causal-discovery priors improving OOD F1 by ≥18%.\nTestable in principle, but the “≥18%” threshold is an unsupported numeric claim; better phrased as “improves OOD performance” unless benchmarked.\n\nHypothesis takeaway: ChatGPT and Copilot propose the most defensible hypotheses; Grok’s is creative but needs removal of unsupported numeric target."
  },
  {
    "objectID": "km_sp2026/assignment2.html#references-accuracy-check",
    "href": "km_sp2026/assignment2.html#references-accuracy-check",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.5 2.5 References (Accuracy Check)",
    "text": "2.5 2.5 References (Accuracy Check)\n\n2.5.1 ChatGPT references\n\nNo explicit reference list was provided. This avoids fabricated citations but reduces academic verifiability.\n\n\n\n2.5.2 Copilot references (checked)\n\nLeCun, Bengio, & Hinton (2015), “Deep learning,” Nature 521:436–444 — Accurate. :contentReferenceoaicite:1\n\nEsteva et al. (2017), “Dermatologist-level classification of skin cancer…,” Nature 542 — Accurate. :contentReferenceoaicite:2\n\nChandola, Banerjee, & Kumar (2009), “Anomaly detection: A survey,” ACM Computing Surveys 41(3) — Accurate. :contentReferenceoaicite:3\n\nCopilot reference takeaway: citations are verifiable and appropriate.\n\n\n2.5.3 Grok 3 references (checked / flagged)\n\nAggarwal (2015), Data Mining: The Textbook (Springer) — Accurate. :contentReferenceoaicite:4\n\nChlingaryan et al. crop yield prediction — the commonly cited Chlingaryan review is 2018 (precision agriculture review), not clearly matching Grok’s “2019 crop yield prediction” citation. This should be treated as uncertain / needs correction. :contentReferenceoaicite:5\n\nLessmann et al. “Benchmarking state-of-the-art classification algorithms for credit scoring” — there is a well-known 2015 European Journal of Operational Research paper with this title; Grok’s “JORS 2019” style detail is likely inconsistent. Treat as needs correction. :contentReferenceoaicite:6\n\nPurushotham et al. “Benchmarking deep learning models on MIMIC-IV,” Nature Medicine 2022 — Not supported by verification; Purushotham’s benchmarking work is known in 2018 (clinical prediction tasks, MIMIC datasets) rather than “Nature Medicine 2022 MIMIC-IV” as stated. Flag as likely inaccurate unless replaced with a verified source. :contentReferenceoaicite:7\n\nGrok reference takeaway: mixed—some accurate, several require correction; numerical claims throughout should not be presented as factual without traceable sources."
  },
  {
    "objectID": "km_sp2026/assignment2.html#summary-table-strengths-and-weaknesses",
    "href": "km_sp2026/assignment2.html#summary-table-strengths-and-weaknesses",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.6 Summary Table (Strengths and Weaknesses)",
    "text": "2.6 Summary Table (Strengths and Weaknesses)\n\n2.6.1 Model | Strengths | Weaknesses / Risks | Best Contribution |\n|—|—|—|—| | ChatGPT | Strong cross-domain synthesis; detailed trends/gaps; clear hypothesis design | Methodology is more generic; lacks explicit references | Integrative synthesis + researchable gaps | | Copilot | Concise, report-ready structure; verifiable references; clear methods | Less cross-domain meta-synthesis; “45 studies” claim lacks trace | Clean structure + credible citations | | Grok 3 | Broad coverage; creative hypothesis; rich tables | Many unverifiable numeric claims; several references inconsistent | Interesting directions, but needs strict verification |"
  },
  {
    "objectID": "km_sp2026/assignment2.html#step-2-conclusion-what-to-fix-in-step-3",
    "href": "km_sp2026/assignment2.html#step-2-conclusion-what-to-fix-in-step-3",
    "title": "Assignment 2: Prompt Exercise",
    "section": "2.7 Step 2 Conclusion (What to fix in Step 3)",
    "text": "2.7 Step 2 Conclusion (What to fix in Step 3)\nBased on this analysis, the refined prompts in Step 3 should: 1. Force reproducible methodology (databases + Boolean query + eligibility + coding scheme). 2. Prohibit fabricated PRISMA counts or performance statistics unless sourced. 3. Require verifiable citations or explicitly label uncertain ones as “candidate references.” 4. Push for cross-domain synthesis (not only descriptive domain summaries)."
  },
  {
    "objectID": "km_sp2026/assignment2.html#chatgpt-output",
    "href": "km_sp2026/assignment2.html#chatgpt-output",
    "title": "Assignment 2: Prompt Exercise",
    "section": "3.1 ChatGPT output",
    "text": "3.1 ChatGPT output\n\n3.1.1 Abstract\nThis systematic literature review (SLR) synthesizes research on how data mining (DM) and machine learning (ML) are applied in three high-impact real-world domains—healthcare, finance, and education. The review summarizes common problem formulations (classification, risk prediction, anomaly detection, natural language processing, recommendation), dominant model families (linear/regularized models, tree-based ensembles, deep learning, and graph-based methods), typical data modalities (tabular, text, image, time series, graph), and evaluation practices. Across domains, the literature indicates recurring socio-technical constraints: distribution shift, data quality and missingness, fairness and accountability, privacy regulation, interpretability demands, and deployment frictions. Emerging trends include foundation models, multimodal learning, privacy-preserving computation, and MLOps standardization, while persistent gaps involve transportability/external validation, causal impact of deployment, domain-aligned interpretability, and secure/robust learning under adversarial settings. A bold, testable hypothesis is proposed linking explanation + uncertainty communication to adoption and performance outcomes in high-stakes decision workflows.\n\n\n\n3.1.2 1. Introduction\nThe proliferation of large-scale digital data has accelerated the adoption of DM and ML across sectors where decision-making is high-stakes and resource-constrained. DM traditionally emphasizes pattern discovery (e.g., clustering, association mining, anomaly detection) and descriptive insights, while ML emphasizes predictive and decision-oriented modeling under uncertainty. In practice, modern applied systems integrate both: feature engineering, supervised prediction, anomaly detection, text mining, and continuous monitoring.\nHealthcare, finance, and education share a common challenge: modeling decisions are embedded in institutional workflows, regulated environments, and heterogeneous populations. As a result, real-world performance depends not only on model accuracy but also on robustness to shift, interpretability for stakeholders, privacy constraints, and governance. This review aims to (i) summarize applications and methods, (ii) provide cross-domain synthesis and “fresh insights” about deployment tradeoffs, (iii) identify trends and gaps, and (iv) propose a testable hypothesis to advance future research.\n\n\n\n3.1.3 2. Methodology (Systematic Review Protocol)\n\n3.1.3.1 2.1 Research Questions\nRQ1: What are the predominant application tasks of DM/ML in healthcare, finance, and education, and what model families are most commonly used?\nRQ2: What constraints (data, evaluation, deployment, governance) shape model performance and real-world adoption across these domains?\n\n\n3.1.3.2 2.2 Search Strategy\nA structured search would typically be conducted in major digital libraries and indexing services such as: - IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (healthcare), and ERIC (education) (supplementary)."
  },
  {
    "objectID": "km_sp2026/assignment2.html#copilot-output",
    "href": "km_sp2026/assignment2.html#copilot-output",
    "title": "Assignment 2: Prompt Exercise",
    "section": "3.2 Copilot output",
    "text": "3.2 Copilot output\n\n3.2.1 Abstract\nThis systematic literature review synthesizes the state-of-the-art applications of Data Mining (DM) and Machine Learning (ML) across three critical domains: Healthcare, Finance, and Education. By analyzing 60 peer-reviewed studies published between 2015 and 2025, this review identifies a convergence of techniques—specifically Deep Learning and Natural Language Processing—while highlighting domain-specific challenges such as interpretability in healthcare, volatility modeling in finance, and privacy in educational data mining. The review reveals a critical gap in cross-domain transfer learning and proposes a bold, testable hypothesis regarding the efficacy of “Federated Transfer Learning” in data-scarce environments.\n\n\n3.2.2 1. Introduction\nThe ubiquity of big data has catalyzed a paradigm shift in decision-making processes. Machine Learning (ML) and Data Mining (DM) have evolved from experimental tools to foundational infrastructure. In healthcare, they drive precision medicine; in finance, they underpin algorithmic trading and fraud detection; and in education, they power adaptive learning platforms. This review aims to dissect the methodological commonalities and divergences across these sectors to inform future interdisciplinary research.\n\n\n3.2.3 2. Methodology\nThis review adheres to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines to ensure rigor and replicability.\n\n3.2.3.1 2.1 Search Strategy\nA systematic search was executed across IEEE Xplore, ACM Digital Library, PubMed, and ERIC (Education Resources Information Center).\nSearch String: (\"Data Mining\" OR \"Machine Learning\" OR \"Deep Learning\" OR \"Neural Networks\") AND (\"Application\" OR \"Case Study\") AND (\"Healthcare\" OR \"Finance\" OR \"Education\" OR \"Learning Analytics\")\n\n\n3.2.3.2 2.2 Inclusion and Exclusion Criteria\n\nInclusion: Peer-reviewed journal articles and high-impact conference proceedings (2015–2025); empirical studies with real-world datasets.\nExclusion: Pre-prints, non-English publications, and pure review papers (to avoid tertiary sourcing).\n\n\n\n3.2.3.3 2.3 Data Extraction & Analysis\nStudies were coded based on: (1) Domain, (2) Problem Type (Classification, Regression, Clustering), (3) Algorithm Family, (4) Dataset Size, and (5) Evaluation Metrics.\n\n\n\n3.2.4 3. Synthesis of Key Findings\n\n3.2.4.1 3.1 Healthcare: From Diagnostics to Prognostics\nThe healthcare sector exhibits the highest adoption of Deep Learning, particularly Convolutional Neural Networks (CNNs) for medical imaging. * Key Finding: ML models for diagnostic imaging (e.g., detecting diabetic retinopathy) have achieved sensitivity and specificity rates exceeding 95%, often outperforming human radiologists in controlled settings. * Methodology Trend: A shift from Support Vector Machines (SVM) to ensemble methods (Random Forest, XGBoost) for Electronic Health Record (EHR) analysis due to their handling of categorical variables and missing data.\n\n\n3.2.4.2 3.2 Finance: Risk, Fraud, and High-Frequency Trading\nFinancial applications prioritize speed and interpretability (for regulatory compliance). * Key Finding: Anomaly detection algorithms (Isolation Forests, Autoencoders) are the standard for credit card fraud detection, reducing false positives by up to 30% compared to rule-based systems. * Methodology Trend: Long Short-Term Memory (LSTM) networks dominate time-series forecasting for stock prices, though Transformer models (e.g., BERT for financial sentiment analysis) are emerging as powerful tools for processing unstructured market news.\n\n\n3.2.4.3 3.3 Education: The Rise of Learning Analytics\nEducational Data Mining (EDM) focuses on predicting student performance and retention. * Key Finding: Predictive models using student interaction logs (LMS data) can identify “at-risk” students as early as the third week of a semester with 85% accuracy. * Methodology Trend: Knowledge Tracing (KT) has evolved from Bayesian Knowledge Tracing (BKT) to Deep Knowledge Tracing (DKT), capturing complex temporal dependencies in student learning curves.\n\n\n\n3.2.5 4. Trends and Gaps\n\n3.2.5.1 4.1 Cross-Cutting Trends\n\nExplainable AI (XAI): Across all three domains, the “black box” nature of Deep Learning is a primary barrier to adoption. Techniques like SHAP (SHapley Additive exPlanations) and LIME are increasingly standard in published research.\nAutoML and Democratization: Tools that automate hyperparameter tuning and model selection are enabling domain experts (doctors, educators) to build models without deep technical expertise.\n\n\n\n3.2.5.2 4.2 Critical Gaps\n\nData Privacy and Ethics: While Differential Privacy is discussed theoretically, practical implementations in shared datasets (especially in Education and Healthcare) remain scarce.\nSiloed Innovation: Techniques successful in one domain (e.g., sequence modeling in NLP) are slow to permeate others (e.g., patient trajectory modeling), indicating a lack of cross-pollination.\nLack of Longitudinal Studies: Most studies report static performance metrics; few evaluate the long-term impact of algorithmic interventions on human outcomes.\n\n\n\n\n3.2.6 5. Proposed Hypothesis\nBased on the synthesis of findings, specifically the struggle with data scarcity in specialized sub-domains (e.g., rare diseases, specific learning disabilities), we propose the following Federated Transfer Learning Hypothesis:\n\nHypothesis: A Federated Transfer Learning (FTL) framework, pre-trained on a generic, large-scale dataset (e.g., general EHRs) and fine-tuned on decentralized, privacy-preserved institutional data (e.g., specific rare disease registries), will achieve a statistically significant improvement (p &lt; 0.05) in F1-score compared to locally trained models, without compromising data privacy standards (measured by epsilon-differential privacy).\n\nExperimental Design for Validation: 1. Control Group: Independent LSTM models trained on isolated hospital datasets for sepsis prediction. 2. Experimental Group: A global LSTM model pre-trained on public MIMIC-III data, then fine-tuned via Federated Averaging across the isolated hospitals. 3. Metrics: Compare AUC-ROC, F1-score, and communication overhead.\n\n\n3.2.7 6. Conclusion\nThe convergence of DM and ML in Healthcare, Finance, and Education is driving unprecedented efficiency and personalization. However, the maturation of these fields depends not on finding more complex algorithms, but on solving the “last mile” problems: interpretability, ethical data governance, and rigorous validation in dynamic, real-world environments. Future research must pivot from maximizing accuracy on static benchmarks to optimizing human-AI collaboration.\n\n\n3.2.8 References\n(Placeholder for BibTeX references)\n\nRajkomar, A., et al. (2018). Scalable and accurate deep learning with electronic health records. NPJ Digital Medicine.\nDixon, M. F., Halperin, I., & Bilokon, P. (2020). Machine Learning in Finance: From Theory to Practice. Springer.\nBaker, R. S., & Inventado, P. S. (2014). Educational data mining and learning analytics. Learning Analytics."
  },
  {
    "objectID": "km_sp2026/assignment2.html#grok-3-output",
    "href": "km_sp2026/assignment2.html#grok-3-output",
    "title": "Assignment 2: Prompt Exercise",
    "section": "3.3 Grok 3 output",
    "text": "3.3 Grok 3 output\n\n3.3.1 Executive Summary\nThis systematic review analyzes 108 empirical studies (2018-2024) across healthcare (42%), finance (35%), and education (23%). Using PRISMA 2020 methodology: Performance: AUC 0.92, F1 0.89\nTechniques: Deep learning 61%, Ensembles 28%\nTrends: XAI +350%, Federated +420%\nGaps: Fairness 11%, Causal &lt;4% Hypothesis: Multi-task causal DM-ML frameworks outperform single-task models by ≥22% in cross-domain transfer for minority subpopulations.\n(128 words) ### 1. Introduction Healthcare produces 2.5 quintillion bytes daily from EHRs, imaging, wearables. Finance processes $6.6T transactions daily. Education platforms serve 1.7B learners. Data mining (clustering, rules, anomalies) and machine learning (supervised/unsupervised/reinforcement) unlock insights. Research Questions: 1. Dominant DM/ML methods per domain? 2. Cross-domain performance patterns? 3. Trends and critical gaps? 4. Testable hypothesis from synthesis?\n\n\n3.3.2 2. Methodology\n\n3.3.2.1 2.1 PRISMA Protocol\nSearch: October 15, 2024 across Scopus (847), PubMed (392), Web of Science (285), IEEE (176), ERIC (89). Query: (“data mining” OR “machine learning”) AND (healthcare OR finance OR education) AND (“real world” OR “case study”) AND (2018:2024)\nFlow: 1,836 → screened 1,424 → full-text 289 → included 108 (deduped 412) #### 2.2 Quality Assessment | Domain | Selection Bias | Performance Bias | Applicability | |——–|—————-|——————|—————| | Healthcare | Low | Low | Moderate | | Finance | Low | Moderate | Low | | Education | Moderate | High | High |\n\n\n\n3.3.3 3. Domain Findings\n\n3.3.3.1 3.1 Healthcare (n=45)\n\n\n\nApplication\nAlgorithm\nDataset\nPerformance\n\n\n\n\nDisease Prediction\nCNN-LSTM\nMIMIC-IV\nAUC 0.94\n\n\nReadmission\nXGBoost\nUCI Heart\nF1 0.91\n\n\nDrug Discovery\nGraph NNs\nPubChem\nP@10 0.88\n\n\nSepsis\nGRU\neICU\n7h lead time\n\n\n\nInsight: Multimodal fusion +17% AUC vs unimodal.\n\n\n3.3.3.2 3.2 Finance (n=38)\n\nFraud: Isolation Forest, Recall 99.7% (2.4B transactions)\nCredit: LightGBM, KS 0.65 (15M loans)\nTrading: Transformer+RL, Sharpe 2.1\n\n\n\n3.3.3.3 3.3 Education (n=25)\n\nDropout prediction: LSTM AUC 0.89 (1M learners)\nPersonalized paths: Bandits +15% completion\nPlagiarism: BERT F1 0.93\n\n\n\n\n3.3.4 4. Cross-Model Collaboration (Synthesis)\n\n3.3.4.1 4.1 What I retained from each model (best elements)\nTo produce a final, academically sound review, I integrated the strongest elements from each model while filtering out unverifiable claims.\n\nFrom ChatGPT (strength: cross-domain synthesis and researchable gaps)\n\nKept the cross-domain synthesis logic (shared deployment constraints across domains).\nKept the richer and more current set of trends and gaps (e.g., MLOps, robustness, privacy-preserving ML, causal ML).\n\nFrom Copilot (strength: replicable methodology template and concise structure)\n\nKept the clearer “protocol-like” structure for Methods (databases, search string, eligibility criteria, and coding fields).\nAdopted its concise domain write-up style (bullets for tasks, model families, data modalities, metrics).\n\nFrom Grok 3 (strength: creative, forward-looking hypothesis framing)\n\nKept the idea of a “bolder” hypothesis that pushes beyond descriptive synthesis.\nDid not retain Grok 3’s numeric PRISMA counts, percentages, performance medians, or global economic-value claims because they were not verifiable from the prompt context.\n\n\n\n\n3.3.4.2 4.2 What I removed or constrained (quality control rules)\nAcross Copilot and Grok 3, the outputs included precise quantitative claims (e.g., number of studies screened, included studies, AUC/accuracy medians, percentage growth). Because I did not conduct an actual database search and did not document a PRISMA flow, these claims were treated as unsubstantiated and excluded from the synthesis.\nTo ensure academic integrity, the final synthesis must: 1. Avoid fabricated PRISMA counts and performance numbers unless explicitly supported by traceable sources. 2. Use verifiable references; if uncertain, label as “candidate reference.” 3. Emphasize cross-domain mechanisms (why deployment succeeds/fails), not just domain-by-domain listing.\n\n\n3.3.4.3 4.3 Synthesis Prompt for My Preferred Model (ChatGPT)\n\n\n\n3.3.5 Applications of Data Mining and Machine Learning in Real-World Domains: A Structured Systematic Literature Review\n\n3.3.5.1 Abstract\nThis structured systematic literature review (SLR) surveys how data mining and machine learning (ML) have been applied across real-world domains, emphasizing methodological patterns, typical data sources, evaluation practices, and persistent limitations. The review synthesizes recurring application families (prediction, classification, anomaly detection, natural language processing, and recommendation), highlights cross-domain trends (foundation models, multimodal learning, privacy-preserving analytics, and MLOps), and identifies research gaps related to external validity, fairness, interpretability, security, and governance. Finally, the review proposes a testable hypothesis linking model transparency to decision-maker trust and downstream adoption in high-stakes settings.\n\n\n3.3.5.2 1. Introduction\nData mining and machine learning have transitioned from primarily academic techniques to core infrastructures supporting decision-making in healthcare, finance, public administration, cybersecurity, education, transportation, and many other sectors. Data mining often emphasizes discovering patterns from large datasets (e.g., clustering, association rules, descriptive analytics), while ML emphasizes predictive and decision-oriented modeling (supervised, unsupervised, reinforcement learning). In practice, real-world systems integrate data collection, feature engineering, model training, validation, deployment, monitoring, and iterative refinement.\nDespite impressive performance gains, real-world adoption exposes limitations: biased training data can encode inequities; complex models may be opaque; models degrade under distribution shift; and high-performing prototypes can fail in deployment due to governance, human factors, or security constraints. This review synthesizes applications and constraints across domains to clarify what is known, what works reliably, and what remains unresolved.\n\n\n3.3.5.3 2. Methodology (Structured SLR Approach)\n\n3.3.5.3.1 2.1 Search Strategy\nA structured search strategy would typically query multidisciplinary databases and digital libraries such as IEEE Xplore, ACM Digital Library, Scopus, Web of Science, PubMed (health), SSRN (policy/econ), and arXiv (preprints). Search strings combine domain terms with method terms.\nExample query structure: - (“machine learning” OR “data mining” OR “deep learning” OR “neural network” OR “random forest” OR “gradient boosting”) AND - (“healthcare” OR “clinical” OR “finance” OR “fraud” OR “cybersecurity” OR “intrusion detection” OR “public policy” OR “government” OR “education” OR “student performance” OR “learning analytics”)\n\n\n3.3.5.3.2 2.2 Inclusion and Exclusion Criteria\nInclusion criteria: - Peer-reviewed journal articles or top-tier conference papers reporting real-world applications or validated prototypes - Clear specification of data source(s), task definition, and evaluation metrics - Empirical results (benchmarking, field deployment, or retrospective validation)\nExclusion criteria: - Opinion pieces without empirical evaluation - Studies lacking reproducible methodological description (e.g., unclear labels, no metrics) - Purely synthetic demonstrations with no domain grounding (unless method is explicitly targeted to domain constraints)\n\n\n3.3.5.3.3 2.3 Screening and Study Selection\nA PRISMA-style process is commonly used: identification → de-duplication → title/abstract screening → full-text eligibility → inclusion. Screening is usually conducted by at least two reviewers, resolving disagreements by consensus. In a classroom exercise without full database access, counts may be omitted; the key is transparent screening logic and consistent application of criteria.\n\n\n3.3.5.3.4 2.4 Synthesis Approach\nGiven domain heterogeneity, synthesis is typically thematic/narrative rather than meta-analysis. Studies can be coded by: 1. Domain 2. Task type 3. Model family 4. Data modality (tabular, text, image, time series, graph) 5. Evaluation metric 6. Deployment context 7. Risk/ethics considerations\n\n\n\n3.3.5.4 3. Findings by Domain (Applications and Key Patterns)\n\n3.3.5.4.1 3.1 Healthcare\nTypical tasks: diagnosis support (classification), risk prediction (readmission, mortality), medical imaging (segmentation/detection), patient trajectory modeling (time series), clinical NLP (extracting diagnoses, medications, symptoms).\nCommon model families: logistic regression and tree-based models for tabular EHR; CNNs/transformers for imaging; RNNs/transformers for sequential records; transformer-based NLP for notes.\nData sources: EHRs, claims, radiology images, pathology slides, wearables, clinical text.\nEvaluation: AUC/ROC, sensitivity/specificity, calibration, clinical utility proxies; external validation is crucial.\nLimitations: dataset shift across hospitals, label noise, missingness, privacy constraints, and the gap between retrospective performance and prospective benefit.\n\n\n3.3.5.4.2 3.2 Finance (Fraud, Risk, Trading, Credit)\nTypical tasks: fraud detection, AML anomaly detection, credit scoring, default prediction, portfolio optimization, trading signals.\nCommon model families: gradient boosting, random forests, logistic regression (auditability), deep learning for sequences, graph ML for transaction networks.\nData sources: transaction logs, credit histories, behavioral signals, network graphs, alternative data (where allowed).\nEvaluation: precision/recall and cost-sensitive metrics; drift monitoring; adversarial robustness tests.\nLimitations: class imbalance, evolving adversaries, regulatory explainability, fairness issues in credit decisions.\n\n\n3.3.5.4.3 3.3 Public Policy and Government Analytics\nTypical tasks: resource allocation, program targeting, inspection prioritization, demand forecasting, text mining for public feedback.\nCommon model families: interpretable models (regularized regression, trees), ensembles, causal ML for heterogeneity, NLP classifiers/topic models.\nData sources: administrative records, census/survey data, service logs, public text.\nEvaluation: predictive performance plus equity-aware evaluation; often human-in-the-loop.\nLimitations: feedback loops, measurement error, ethical constraints, governance and accountability gaps.\n\n\n3.3.5.4.4 3.4 Cybersecurity\nTypical tasks: intrusion detection, malware classification, phishing detection, anomaly detection, threat intelligence extraction from text.\nCommon model families: classical ML for engineered features; deep learning for sequences; graph ML for attack graphs; transformers for security text.\nData sources: logs, network flows, endpoint telemetry, binaries, security reports.\nEvaluation: precision/recall under class imbalance; robustness to concept drift and adversarial manipulation.\nLimitations: labeled data scarcity, operational false-positive costs, adversarial adaptation, real-time constraints.\n\n\n3.3.5.4.5 3.5 Education (Learning Analytics)\nTypical tasks: student performance prediction, dropout risk, mastery estimation, item recommendation, automated feedback from text.\nCommon model families: regression/boosting for tabular LMS logs; sequence models for clickstreams; NLP for essays and discussion posts; knowledge tracing.\nData sources: LMS event logs, assessment data, enrollment records, student-generated text.\nEvaluation: prediction accuracy plus pedagogical validity; fairness across groups; impact on learning outcomes if deployed.\nLimitations: weak causal identification, privacy and consent concerns, risk of stigmatization from risk scores.\n\n\n\n3.3.5.5 4. Cross-Domain Synthesis: What Works and Why\nAcross domains, successful applications tend to share: 1. Well-specified decision context (triage, prioritization, detection thresholds) 2. Data quality pipelines (missingness handling, feature governance) 3. Evaluation beyond accuracy (calibration, stability under shift, fairness, cost-aware metrics) 4. Human-in-the-loop design (interfaces and explanations shape trust) 5. Deployment and monitoring (drift detection, retraining policies, incident response)\n\n\n3.3.5.6 5. Emerging Trends (≥5)\n\nFoundation models and domain adaptation\n\nMultimodal learning (text + image + tabular + time series)\n\nPrivacy-preserving ML (federated learning, differential privacy, secure computation)\n\nCausal ML and policy learning (prediction + intervention design)\n\nMLOps and continuous monitoring (versioning, drift detection, governance)\n\nRobustness/adversarial ML (fraud and cybersecurity)\n\nExplainability as a product and compliance requirement\n\n\n\n3.3.5.7 6. Research Gaps (≥5)\n\nExternal validity and transportability across sites and populations\n\nCausal impact of deployment on outcomes (beyond retrospective metrics)\n\nStandardized fairness/harm metrics for domain-specific decisions\n\nOperational interpretability aligned to practitioner needs\n\nData governance and accountability for model errors and harms\n\nSecurity of ML systems (poisoning, theft, supply-chain risks)\n\nLong-term monitoring and retraining policy evaluation under nonstationarity\n\n\n\n3.3.5.8 7. Proposed Testable Hypothesis\nH1: In high-stakes decision settings, providing decision-makers with transparent model explanations (interpretable features + calibrated uncertainty) increases trust and adoption of ML recommendations compared with prediction-only outputs.\n\n3.3.5.8.1 Operationalization\n\nIndependent variable: explanation condition\n\n0 = prediction-only\n\n1 = prediction + explanation + uncertainty\n\nDependent variables:\n\nTrust: survey scale (perceived reliability/fairness)\n\nAdoption: rate of following model recommendation or decision alignment\n\nDesign: randomized experiment (field or lab) among domain professionals\n\nTest: difference in means / regression controlling for experience and case complexity\n\n\n\n\n3.3.5.9 8. Conclusion\nApplications of data mining and ML are widespread across healthcare, finance, policy, cybersecurity, and education. Adoption depends not only on model performance but also on data governance, robust evaluation, user-aligned interpretability, and deployment monitoring. Future work should prioritize transportable validation, causal impact evaluation, standardized harm measurement, and institutional accountability."
  },
  {
    "objectID": "km_sp2026/assignment2.html#how-did-each-model-approach-the-systematic-review-differently",
    "href": "km_sp2026/assignment2.html#how-did-each-model-approach-the-systematic-review-differently",
    "title": "Assignment 2: Prompt Exercise",
    "section": "4.1 How did each model approach the systematic review differently?",
    "text": "4.1 How did each model approach the systematic review differently?\n\n4.1.1 ChatGPT\nChatGPT approached the task as a cross-domain conceptual synthesis. It emphasized (1) a clean SLR-like structure, (2) consistent domain-by-domain summaries (tasks, model families, data, evaluation, limitations), and (3) a strong cross-domain “what works and why” section. Its methodology description was credible but intentionally conservative—describing how an SLR should be done rather than asserting specific PRISMA counts or performance statistics.\n\n\n4.1.2 Copilot\nCopilot focused on producing a report-ready template with clear headings and a direct PRISMA framing. It typically excelled at concise structuring (methods → findings → trends/gaps → hypothesis) and gave concrete components such as a search string and coding fields. However, it tended to state specific scope claims (e.g., “X studies analyzed,” “2015–2025”) without showing a traceable screening log, so those details need user verification before being treated as factual.\n\n\n4.1.3 Grok 3\nGrok 3 prioritized a high-confidence, metrics-driven narrative. It presented a very “scientific-looking” review with detailed counts, percentages, pooled metrics, and strongly quantified trends and effects. While this style can look impressive, it introduced the highest risk of unverifiable or fabricated quantitative claims when the prompt did not provide underlying data. In my workflow, Grok 3 was most useful for generating bold hypotheses and highlighting possible frontier directions—but its numbers required strict filtering."
  },
  {
    "objectID": "km_sp2026/assignment2.html#which-prompt-refinements-yielded-the-best-results-for-each-model",
    "href": "km_sp2026/assignment2.html#which-prompt-refinements-yielded-the-best-results-for-each-model",
    "title": "Assignment 2: Prompt Exercise",
    "section": "4.2 Which prompt refinements yielded the best results for each model?",
    "text": "4.2 Which prompt refinements yielded the best results for each model?\n\n4.2.1 For ChatGPT\nFor ChatGPT, the most effective refinements were: - Forcing a reproducible Methods protocol (databases, one Boolean query, explicit inclusion/exclusion criteria, coding framework). - Requiring ≥5 trends and ≥5 gaps as researchable statements, which improved specificity. - Adding an integrity rule (“no fabricated PRISMA counts or performance numbers”) strengthened academic defensibility.\n\n\n4.2.2 For Copilot\nFor Copilot, the most effective refinements were: - Enforcing fixed headings and a “must-follow” outline (RQs → Methods → Findings → Trends/Gaps → Hypothesis → References). - Explicitly instructing: “If counts are unknown, say ‘not available’”, which reduces unsupported claims. - Requiring a coding framework (domain/task/modality/model/metric/deployment/risks) improved systematic clarity.\n\n\n4.2.3 For Grok 3\nFor Grok 3, the most effective refinements were: - Adding strict constraints: no numeric screening counts, no pooled performance metrics, no growth percentages unless cited. - Requiring that uncertain citations be labeled “candidate references” rather than asserted as true. - Asking for “fresh insights” as tradeoffs/tensions (accuracy vs interpretability, privacy vs utility, robustness vs performance) instead of numeric-heavy summaries."
  },
  {
    "objectID": "km_sp2026/assignment2.html#what-did-you-learn-about-leveraging-ai-for-structured-academic-reviews",
    "href": "km_sp2026/assignment2.html#what-did-you-learn-about-leveraging-ai-for-structured-academic-reviews",
    "title": "Assignment 2: Prompt Exercise",
    "section": "4.3 What did you learn about leveraging AI for structured academic reviews?",
    "text": "4.3 What did you learn about leveraging AI for structured academic reviews?\n\nAI is strongest at structure and synthesis, not at unverifiable specifics.\nThe models can reliably produce coherent organization (SLR headings), domain taxonomies, and cross-domain themes. But unless the user provides the evidence base (search results, screened papers), AI may generate overly specific numbers (PRISMA counts, pooled AUC) that should not be treated as factual.\nPrompting must operationalize rigor.\nThe best results came from prompts that required: explicit databases, a reproducible Boolean query, eligibility criteria, a screening workflow description, and a coding framework. These constraints transform “general summaries” into a workflow-aligned SLR draft.\nIntegrity constraints are essential for academic use.\nAdding rules like “do not fabricate counts or performance metrics” and “label uncertain citations as candidate references” greatly improved reliability. This also clarified which parts of the output are safe to publish in a course website.\nCross-model collaboration works best when each model is assigned a role.\nIn synthesis, I treated ChatGPT as the main integrator for cross-domain reasoning, Copilot as a structure/methods template engine, and Grok 3 as an idea generator for bold hypotheses and emerging directions—while filtering out unsupported quantitative claims.\n\nOverall, the process showed that AI can accelerate academic drafting and conceptual synthesis, but the user must impose methodological discipline and verification rules to produce an academically credible systematic review."
  },
  {
    "objectID": "Lab02.html",
    "href": "Lab02.html",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "(Adapted from ISLR Chapter 3 Lab: Introduction to R)\n\n\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),] # What does -c() do?\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A) # Dimensions\n\n[1] 4 4\n\n\n\n\n\n\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\")\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\",header=T,na.strings=\"?\") \nAuto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\") # read csv file\n# Which function reads data faster?\n\n# Try using this simple method\n# time1 = proc.time()\n# Auto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\",header=T,na.strings=\"?\")\n# proc.time()-time1\n\n# Check on data\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,] # select rows\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto) # Notice the difference?\n\n[1] 397   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\n\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\n\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\n\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\n\nThe downloaded binary packages are in\n    /var/folders/x7/9xc7q6bd0zb1gtw3t8j09jfw0000gn/T//RtmpdDTqNQ/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\n\n\n\n\n\n\n\n\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\n\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\n\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lab02.html#indexing-data-using",
    "href": "Lab02.html#indexing-data-using",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "A=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),] # What does -c() do?\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A) # Dimensions\n\n[1] 4 4"
  },
  {
    "objectID": "Lab02.html#loading-data-from-github-remote",
    "href": "Lab02.html#loading-data-from-github-remote",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "Auto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\")\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\",header=T,na.strings=\"?\") \nAuto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\") # read csv file\n# Which function reads data faster?\n\n# Try using this simple method\n# time1 = proc.time()\n# Auto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\",header=T,na.strings=\"?\")\n# proc.time()-time1\n\n# Check on data\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,] # select rows\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto) # Notice the difference?\n\n[1] 397   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\""
  },
  {
    "objectID": "Lab02.html#load-data-from-islr-website",
    "href": "Lab02.html#load-data-from-islr-website",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "Auto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9"
  },
  {
    "objectID": "Lab02.html#additional-graphical-and-numerical-summaries",
    "href": "Lab02.html#additional-graphical-and-numerical-summaries",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60"
  },
  {
    "objectID": "Lab02.html#linear-regression",
    "href": "Lab02.html#linear-regression",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "ptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\n\nThe downloaded binary packages are in\n    /var/folders/x7/9xc7q6bd0zb1gtw3t8j09jfw0000gn/T//RtmpdDTqNQ/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375"
  },
  {
    "objectID": "Lab02.html#multiple-linear-regression",
    "href": "Lab02.html#multiple-linear-regression",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "lm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)"
  },
  {
    "objectID": "Lab02.html#non-linear-transformations-of-the-predictors",
    "href": "Lab02.html#non-linear-transformations-of-the-predictors",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "lm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lab02.html#qualitative-predictors",
    "href": "Lab02.html#qualitative-predictors",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1"
  },
  {
    "objectID": "Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "href": "Lab02.html#interaction-terms-including-interaction-and-single-effects",
    "title": "EPPS 6323: Lab02 R programming basics II",
    "section": "",
    "text": "summary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "km_sp2026/assignment1.html",
    "href": "km_sp2026/assignment1.html",
    "title": "Assignment 1",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9960263\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x\n\n\n\n\n\n\n\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),] # What does -c() do?\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A) # Dimensions\n\n[1] 4 4\n\n\n\n\n\n\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\")\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\",header=T,na.strings=\"?\") \nAuto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\") # read csv file\n# Which function reads data faster?\n\n# Try using this simple method\n# time1 = proc.time()\n# Auto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\",header=T,na.strings=\"?\")\n# proc.time()-time1\n\n# Check on data\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,] # select rows\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto) # Notice the difference?\n\n[1] 397   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\n\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\n\n\n# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\n\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\n\nThe downloaded binary packages are in\n    /var/folders/x7/9xc7q6bd0zb1gtw3t8j09jfw0000gn/T//Rtmpf8BIRo/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\n\n\n\n\n\n\n\n\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\n\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\n\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "km_sp2026/assignment1.html#create-object-using-the-assignment-operator--",
    "href": "km_sp2026/assignment1.html#create-object-using-the-assignment-operator--",
    "title": "Assignment 1",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)"
  },
  {
    "objectID": "km_sp2026/assignment1.html#using-function",
    "href": "km_sp2026/assignment1.html#using-function",
    "title": "Assignment 1",
    "section": "",
    "text": "length(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3"
  },
  {
    "objectID": "km_sp2026/assignment1.html#using---operators",
    "href": "km_sp2026/assignment1.html#using---operators",
    "title": "Assignment 1",
    "section": "",
    "text": "x+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!"
  },
  {
    "objectID": "km_sp2026/assignment1.html#matrix-operations",
    "href": "km_sp2026/assignment1.html#matrix-operations",
    "title": "Assignment 1",
    "section": "",
    "text": "?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9960263\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)"
  },
  {
    "objectID": "km_sp2026/assignment1.html#simple-descriptive-statistics-base",
    "href": "km_sp2026/assignment1.html#simple-descriptive-statistics-base",
    "title": "Assignment 1",
    "section": "",
    "text": "mean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768"
  },
  {
    "objectID": "km_sp2026/assignment1.html#visualization-using-r-graphics-without-packages",
    "href": "km_sp2026/assignment1.html#visualization-using-r-graphics-without-packages",
    "title": "Assignment 1",
    "section": "",
    "text": "x=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "km_sp2026/assignment1.html#indexing-data-using",
    "href": "km_sp2026/assignment1.html#indexing-data-using",
    "title": "Assignment 1",
    "section": "",
    "text": "A=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),] # What does -c() do?\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A) # Dimensions\n\n[1] 4 4"
  },
  {
    "objectID": "km_sp2026/assignment1.html#loading-data-from-github-remote",
    "href": "km_sp2026/assignment1.html#loading-data-from-github-remote",
    "title": "Assignment 1",
    "section": "",
    "text": "Auto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\")\nAuto=read.table(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.data\",header=T,na.strings=\"?\") \nAuto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\") # read csv file\n# Which function reads data faster?\n\n# Try using this simple method\n# time1 = proc.time()\n# Auto=read.csv(\"https://raw.githubusercontent.com/datageneration/knowledgemining/master/data/Auto.csv\",header=T,na.strings=\"?\")\n# proc.time()-time1\n\n# Check on data\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,] # select rows\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto) # Notice the difference?\n\n[1] 397   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\""
  },
  {
    "objectID": "km_sp2026/assignment1.html#load-data-from-islr-website",
    "href": "km_sp2026/assignment1.html#load-data-from-islr-website",
    "title": "Assignment 1",
    "section": "",
    "text": "Auto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9"
  },
  {
    "objectID": "km_sp2026/assignment1.html#additional-graphical-and-numerical-summaries",
    "href": "km_sp2026/assignment1.html#additional-graphical-and-numerical-summaries",
    "title": "Assignment 1",
    "section": "",
    "text": "# plot(cylinders, mpg)\nplot(Auto$cylinders, Auto$mpg)\n\n\n\n\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\n\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\n\n\n\n\nhist(mpg)\n\n\n\n\n\n\n\nhist(mpg,col=2)\n\n\n\n\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\n\n\n\n\nplot(horsepower,mpg)\n\n\n\n\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60"
  },
  {
    "objectID": "km_sp2026/assignment1.html#linear-regression",
    "href": "km_sp2026/assignment1.html#linear-regression",
    "title": "Assignment 1",
    "section": "",
    "text": "ptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\n\nThe downloaded binary packages are in\n    /var/folders/x7/9xc7q6bd0zb1gtw3t8j09jfw0000gn/T//Rtmpf8BIRo/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\n\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\n\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\n\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\n\n\n\n\nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\nwhich.max(hatvalues(lm.fit))\n\n375 \n375"
  },
  {
    "objectID": "km_sp2026/assignment1.html#multiple-linear-regression",
    "href": "km_sp2026/assignment1.html#multiple-linear-regression",
    "title": "Assignment 1",
    "section": "",
    "text": "lm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  &lt; 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)"
  },
  {
    "objectID": "km_sp2026/assignment1.html#non-linear-transformations-of-the-predictors",
    "href": "km_sp2026/assignment1.html#non-linear-transformations-of-the-predictors",
    "title": "Assignment 1",
    "section": "",
    "text": "lm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***\nlstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\nplot(lm.fit2)\n\n\n\n\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       22.5328     0.2318  97.197  &lt; 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  &lt; 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  &lt; 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: &lt; 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -76.488      5.028  -15.21   &lt;2e-16 ***\nlog(rm)       54.055      2.739   19.73   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "km_sp2026/assignment1.html#qualitative-predictors",
    "href": "km_sp2026/assignment1.html#qualitative-predictors",
    "title": "Assignment 1",
    "section": "",
    "text": "# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  &lt; 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  &lt; 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  &lt; 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  &lt; 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: &lt; 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1"
  },
  {
    "objectID": "km_sp2026/assignment1.html#interaction-terms-including-interaction-and-single-effects",
    "href": "km_sp2026/assignment1.html#interaction-terms-including-interaction-and-single-effects",
    "title": "Assignment 1",
    "section": "",
    "text": "summary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "km_sp2026/index.html",
    "href": "km_sp2026/index.html",
    "title": "EPPS 6323 Knowledge Mining",
    "section": "",
    "text": "Assignment 1"
  },
  {
    "objectID": "km_sp2026/index.html#assignments",
    "href": "km_sp2026/index.html#assignments",
    "title": "EPPS 6323 Knowledge Mining",
    "section": "",
    "text": "Assignment 1"
  },
  {
    "objectID": "Lab01.html",
    "href": "Lab01.html",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)\n\n\n\n\n\nlength(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3\n\n\n\n\n\n\nx+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9940904\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768\n\n\n\n\n\n\nx=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "Lab01.html#create-object-using-the-assignment-operator--",
    "href": "Lab01.html#create-object-using-the-assignment-operator--",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x &lt;- c(1,3,2,5)\nx\n\n[1] 1 3 2 5\n\nx = c(1,6,2)\nx\n\n[1] 1 6 2\n\ny = c(1,4,3)"
  },
  {
    "objectID": "Lab01.html#using-function",
    "href": "Lab01.html#using-function",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "length(x)  # What does length() do?\n\n[1] 3\n\nlength(y)\n\n[1] 3"
  },
  {
    "objectID": "Lab01.html#using---operators",
    "href": "Lab01.html#using---operators",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x+y\n\n[1]  2 10  5\n\nls() # List objects in the environment\n\n[1] \"x\" \"y\"\n\nrm(x,y) # Remove objects\nls()\n\ncharacter(0)\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!"
  },
  {
    "objectID": "Lab01.html#matrix-operations",
    "href": "Lab01.html#matrix-operations",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "?matrix\nx=matrix(data=c(1,2,3,4), nrow=2, ncol=2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx=matrix(c(1,2,3,4),2,2)\nmatrix(c(1,2,3,4),2,2,byrow=T) # What about byrow=F?\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx=rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny=x+rnorm(50,mean=50,sd=.1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9940904\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny=rnorm(100)"
  },
  {
    "objectID": "Lab01.html#simple-descriptive-statistics-base",
    "href": "Lab01.html#simple-descriptive-statistics-base",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "mean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768"
  },
  {
    "objectID": "Lab01.html#visualization-using-r-graphics-without-packages",
    "href": "Lab01.html#visualization-using-r-graphics-without-packages",
    "title": "EPPS 6323: Lab01 R programming basics I",
    "section": "",
    "text": "x=rnorm(100)\ny=rnorm(100)\nplot(x,y)\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"firebrick\") # Scatterplot for two numeric variables by default\n\n\n\n\n\n\n\nplot(x,y, pch=20, col = \"steelblue\",xlab=\"this is the x-axis\",ylab=\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\n\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\nplot(x,y,pch=20, col=\"forestgreen\") # Try different colors?\ndev.off() # Close the file using the dev.off function\n\nquartz_off_screen \n                2 \n\nx=seq(1,10) # Same as x=c(1:10)\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=1:10\nx\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx=seq(-pi,pi,length=50)\ny=x"
  },
  {
    "objectID": "im_sp2026/assignment2.html#q1.-relation-schema-vs-relation-vs-instance",
    "href": "im_sp2026/assignment2.html#q1.-relation-schema-vs-relation-vs-instance",
    "title": "EPPS 6354 Assignment 2",
    "section": "Q1. relation schema vs relation vs instance",
    "text": "Q1. relation schema vs relation vs instance\nRelation schema (schema)\nThe definition/blueprint of a table: its name, attributes (columns), data types/domains, and constraints (e.g., primary key, foreign key).\nExample: student(SID, name, dept_name, tot_cred) with SID as the primary key.\nRelation (relation/table definition under a schema)\nThe table itself as a concept: the set of tuples (rows) that must follow the schema’s structure and constraints.\nExample: the Student relation that contains all student records and always has the four columns defined above.\nInstance (relation instance / snapshot)\nThe actual data currently stored in that relation at a specific time (a snapshot of rows).\nExample (today’s Student instance): (1001, “Alice”, “Poli Sci”, 30) (1002, “Bob”, “Cybersecurity”, 18)\nSchema = design, Relation = the table concept, Instance = current contents."
  },
  {
    "objectID": "im_sp2026/assignment2.html#q2.-bank-database-entities-relationships",
    "href": "im_sp2026/assignment2.html#q2.-bank-database-entities-relationships",
    "title": "EPPS 6354 Assignment 2",
    "section": "Q2. Bank database (entities & relationships)",
    "text": "Q2. Bank database (entities & relationships)\nGiven relations: - branch(branch_name, branch_city, assets) - customer(ID, customer_name, customer_street, customer_city) - loan(loan_number, branch_name, amount) - borrower(ID, loan_number) - account(account_number, branch_name, balance) - depositor(ID, account_number)"
  },
  {
    "objectID": "im_sp2026/assignment2.html#q2.-schema-diagram",
    "href": "im_sp2026/assignment2.html#q2.-schema-diagram",
    "title": "EPPS 6354 Assignment 2",
    "section": "Q2. Schema diagram",
    "text": "Q2. Schema diagram\n\n\n\n\n\nerDiagram\n  BRANCH ||--o{ LOAN : has\n  BRANCH ||--o{ ACCOUNT : has\n  CUSTOMER ||--o{ BORROWER : borrows\n  LOAN ||--o{ BORROWER : is_borrowed_by\n  CUSTOMER ||--o{ DEPOSITOR : deposits\n  ACCOUNT ||--o{ DEPOSITOR : is_owned_by\n\n  BRANCH {\n    string branch_name PK\n    string branch_city\n    numeric assets\n  }\n\n  CUSTOMER {\n    int ID PK\n    string customer_name\n    string customer_street\n    string customer_city\n  }\n\n  LOAN {\n    string loan_number PK\n    string branch_name FK\n    numeric amount\n  }\n\n  ACCOUNT {\n    string account_number PK\n    string branch_name FK\n    numeric balance\n  }\n\n  BORROWER {\n    int ID FK\n    string loan_number FK\n  }\n\n  DEPOSITOR {\n    int ID FK\n    string account_number FK\n  }"
  },
  {
    "objectID": "im_sp2026/assignment2.html#q3.-primary-keys-and-foreign-keys",
    "href": "im_sp2026/assignment2.html#q3.-primary-keys-and-foreign-keys",
    "title": "EPPS 6354 Assignment 2",
    "section": "Q3. Primary keys and foreign keys",
    "text": "Q3. Primary keys and foreign keys\n(i) Appropriate primary keys (PK)\n\nbranch: branch_name (PK)\n\ncustomer: ID (PK)\n\nloan: loan_number (PK)\n\naccount: account_number (PK)\n\nborrower: (ID, loan_number) (composite PK)\n\ndepositor: (ID, account_number) (composite PK)\n\n(ii) Appropriate foreign keys (FK)\n\nloan.branch_name → branch.branch_name\naccount.branch_name → branch.branch_name\nborrower.ID → customer.ID\nborrower.loan_number → loan.loan_number\ndepositor.ID → customer.ID\ndepositor.account_number → account.account_number"
  },
  {
    "objectID": "im_sp2026/assignment2.html#q4.-two-ways-aillms-help-manage-or-query-a-database-35-sentences",
    "href": "im_sp2026/assignment2.html#q4.-two-ways-aillms-help-manage-or-query-a-database-35-sentences",
    "title": "EPPS 6354 Assignment 2",
    "section": "Q4. Two ways AI/LLMs help manage or query a database (3–5 sentences)",
    "text": "Q4. Two ways AI/LLMs help manage or query a database (3–5 sentences)\n\nNatural-language to SQL: An LLM can translate a user’s question (in plain English) into a correct SQL query and explain what the query does. This saves time on SQL syntax and reduces errors such as incorrect joins or missing filters, improving efficiency and accuracy compared with writing queries manually.\nPerformance + data-quality assistance: AI can recommend indexes and query rewrites when a query is slow, and it can flag data-quality issues (missing keys, inconsistent formats, unusual values) during cleaning or ETL. These suggestions reduce debugging time and improve reliability compared with traditional manual trial-and-error checks."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spring 2026 Course Portfolio",
    "section": "",
    "text": "Welcome! This site hosts Jing Tao’s course assignments for Spring 2026."
  },
  {
    "objectID": "index.html#courses",
    "href": "index.html#courses",
    "title": "Spring 2026 Course Portfolio",
    "section": "Courses",
    "text": "Courses\n\nEPPS 6323 Knowledge Mining (Spring 2026)\nEPPS 6354 Information Management (Spring 2026)"
  }
]